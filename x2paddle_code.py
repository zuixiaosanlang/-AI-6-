import paddle
import math


class TFModel(paddle.nn.Layer):
    def __init__(self):
        super(TFModel, self).__init__()
        self.vgg19_sub_y = self.create_parameter(shape=[1, 1, 1, 3], attr='vgg19_sub_y', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape = self.create_parameter(shape=[4], attr='Shape', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_1 = self.create_parameter(shape=[4], attr='Shape_1', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_2 = self.create_parameter(shape=[4], attr='Shape_2', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_3 = self.create_parameter(shape=[4], attr='Shape_3', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_4 = self.create_parameter(shape=[4], attr='Shape_4', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_5 = self.create_parameter(shape=[4], attr='Shape_5', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_6 = self.create_parameter(shape=[4], attr='Shape_6', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_7 = self.create_parameter(shape=[4], attr='Shape_7', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_8 = self.create_parameter(shape=[4], attr='Shape_8', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_9 = self.create_parameter(shape=[4], attr='Shape_9', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_0att2_bottleneck_fc_kernel = self.create_parameter(shape=[128, 16], attr='g_aggi_0att2_bottleneck_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_0att2_bottleneck_fc_bias = self.create_parameter(shape=[16], attr='g_aggi_0att2_bottleneck_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_0att2_recover_fc_kernel = self.create_parameter(shape=[16, 128], attr='g_aggi_0att2_recover_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_0att2_recover_fc_bias = self.create_parameter(shape=[128], attr='g_aggi_0att2_recover_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_0att2_bottleneck_fc_kernel = self.create_parameter(shape=[128, 16], attr='g_aggm_0att2_bottleneck_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_0att2_bottleneck_fc_bias = self.create_parameter(shape=[16], attr='g_aggm_0att2_bottleneck_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_0att2_recover_fc_kernel = self.create_parameter(shape=[16, 128], attr='g_aggm_0att2_recover_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_0att2_recover_fc_bias = self.create_parameter(shape=[128], attr='g_aggm_0att2_recover_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_1att2_bottleneck_fc_kernel = self.create_parameter(shape=[192, 24], attr='g_aggi_1att2_bottleneck_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_1att2_bottleneck_fc_bias = self.create_parameter(shape=[24], attr='g_aggi_1att2_bottleneck_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_1att2_recover_fc_kernel = self.create_parameter(shape=[24, 192], attr='g_aggi_1att2_recover_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_1att2_recover_fc_bias = self.create_parameter(shape=[192], attr='g_aggi_1att2_recover_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_1att2_bottleneck_fc_kernel = self.create_parameter(shape=[192, 24], attr='g_aggm_1att2_bottleneck_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_1att2_bottleneck_fc_bias = self.create_parameter(shape=[24], attr='g_aggm_1att2_bottleneck_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_1att2_recover_fc_kernel = self.create_parameter(shape=[24, 192], attr='g_aggm_1att2_recover_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_1att2_recover_fc_bias = self.create_parameter(shape=[192], attr='g_aggm_1att2_recover_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_2att2_bottleneck_fc_kernel = self.create_parameter(shape=[192, 24], attr='g_aggi_2att2_bottleneck_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_2att2_bottleneck_fc_bias = self.create_parameter(shape=[24], attr='g_aggi_2att2_bottleneck_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_2att2_recover_fc_kernel = self.create_parameter(shape=[24, 192], attr='g_aggi_2att2_recover_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_2att2_recover_fc_bias = self.create_parameter(shape=[192], attr='g_aggi_2att2_recover_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_2att2_bottleneck_fc_kernel = self.create_parameter(shape=[192, 24], attr='g_aggm_2att2_bottleneck_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_2att2_bottleneck_fc_bias = self.create_parameter(shape=[24], attr='g_aggm_2att2_bottleneck_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_2att2_recover_fc_kernel = self.create_parameter(shape=[24, 192], attr='g_aggm_2att2_recover_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_2att2_recover_fc_bias = self.create_parameter(shape=[192], attr='g_aggm_2att2_recover_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_3att2_bottleneck_fc_kernel = self.create_parameter(shape=[256, 32], attr='g_aggi_3att2_bottleneck_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_3att2_bottleneck_fc_bias = self.create_parameter(shape=[32], attr='g_aggi_3att2_bottleneck_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_3att2_recover_fc_kernel = self.create_parameter(shape=[32, 256], attr='g_aggi_3att2_recover_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggi_3att2_recover_fc_bias = self.create_parameter(shape=[256], attr='g_aggi_3att2_recover_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_3att2_bottleneck_fc_kernel = self.create_parameter(shape=[256, 32], attr='g_aggm_3att2_bottleneck_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_3att2_bottleneck_fc_bias = self.create_parameter(shape=[32], attr='g_aggm_3att2_bottleneck_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_3att2_recover_fc_kernel = self.create_parameter(shape=[32, 256], attr='g_aggm_3att2_recover_fc_kernel', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.g_aggm_3att2_recover_fc_bias = self.create_parameter(shape=[256], attr='g_aggm_3att2_recover_fc_bias', dtype='float32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_10 = self.create_parameter(shape=[4], attr='Shape_10', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_11 = self.create_parameter(shape=[4], attr='Shape_11', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_12 = self.create_parameter(shape=[4], attr='Shape_12', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_13 = self.create_parameter(shape=[4], attr='Shape_13', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_14 = self.create_parameter(shape=[4], attr='Shape_14', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_15 = self.create_parameter(shape=[4], attr='Shape_15', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_16 = self.create_parameter(shape=[4], attr='Shape_16', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_17 = self.create_parameter(shape=[4], attr='Shape_17', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_18 = self.create_parameter(shape=[4], attr='Shape_18', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_19 = self.create_parameter(shape=[4], attr='Shape_19', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_20 = self.create_parameter(shape=[4], attr='Shape_20', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_21 = self.create_parameter(shape=[4], attr='Shape_21', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_22 = self.create_parameter(shape=[4], attr='Shape_22', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_23 = self.create_parameter(shape=[4], attr='Shape_23', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_24 = self.create_parameter(shape=[4], attr='Shape_24', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.Shape_25 = self.create_parameter(shape=[4], attr='Shape_25', dtype='int32', default_initializer=paddle.nn.initializer.Constant(value=0.0))
        self.conv0 = paddle.nn.Conv2D(weight_attr='conv0.weight', bias_attr='vgg19_Const_1', in_channels=3, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.relu0 = paddle.nn.ReLU()
        self.conv1 = paddle.nn.Conv2D(weight_attr='conv1.weight', bias_attr='vgg19_Const_3', in_channels=64, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.relu1 = paddle.nn.ReLU()
        self.pool0 = paddle.nn.AvgPool2D(kernel_size=[2, 2], stride=2, padding='SAME')
        self.conv2 = paddle.nn.Conv2D(weight_attr='conv2.weight', bias_attr='vgg19_Const_5', in_channels=64, out_channels=128, kernel_size=[3, 3], padding='SAME')
        self.relu2 = paddle.nn.ReLU()
        self.conv3 = paddle.nn.Conv2D(weight_attr='conv3.weight', bias_attr='vgg19_Const_7', in_channels=128, out_channels=128, kernel_size=[3, 3], padding='SAME')
        self.relu3 = paddle.nn.ReLU()
        self.pool1 = paddle.nn.AvgPool2D(kernel_size=[2, 2], stride=2, padding='SAME')
        self.conv4 = paddle.nn.Conv2D(weight_attr='conv4.weight', bias_attr='vgg19_Const_9', in_channels=128, out_channels=256, kernel_size=[3, 3], padding='SAME')
        self.relu4 = paddle.nn.ReLU()
        self.conv5 = paddle.nn.Conv2D(weight_attr='conv5.weight', bias_attr='vgg19_Const_11', in_channels=256, out_channels=256, kernel_size=[3, 3], padding='SAME')
        self.relu5 = paddle.nn.ReLU()
        self.conv6 = paddle.nn.Conv2D(weight_attr='conv6.weight', bias_attr='vgg19_Const_13', in_channels=256, out_channels=256, kernel_size=[3, 3], padding='SAME')
        self.relu6 = paddle.nn.ReLU()
        self.conv7 = paddle.nn.Conv2D(weight_attr='conv7.weight', bias_attr='vgg19_Const_15', in_channels=256, out_channels=256, kernel_size=[3, 3], padding='SAME')
        self.relu7 = paddle.nn.ReLU()
        self.pool2 = paddle.nn.AvgPool2D(kernel_size=[2, 2], stride=2, padding='SAME')
        self.conv8 = paddle.nn.Conv2D(weight_attr='conv8.weight', bias_attr='vgg19_Const_17', in_channels=256, out_channels=512, kernel_size=[3, 3], padding='SAME')
        self.relu8 = paddle.nn.ReLU()
        self.conv9 = paddle.nn.Conv2D(weight_attr='conv9.weight', bias_attr='vgg19_Const_19', in_channels=512, out_channels=512, kernel_size=[3, 3], padding='SAME')
        self.relu9 = paddle.nn.ReLU()
        self.conv10 = paddle.nn.Conv2D(weight_attr='conv10.weight', bias_attr='vgg19_Const_21', in_channels=512, out_channels=512, kernel_size=[3, 3], padding='SAME')
        self.relu10 = paddle.nn.ReLU()
        self.conv11 = paddle.nn.Conv2D(weight_attr='conv11.weight', bias_attr='vgg19_Const_23', in_channels=512, out_channels=512, kernel_size=[3, 3], padding='SAME')
        self.relu11 = paddle.nn.ReLU()
        self.pool3 = paddle.nn.AvgPool2D(kernel_size=[2, 2], stride=2, padding='SAME')
        self.conv12 = paddle.nn.Conv2D(weight_attr='conv12.weight', bias_attr='vgg19_Const_25', in_channels=512, out_channels=512, kernel_size=[3, 3], padding='SAME')
        self.relu12 = paddle.nn.ReLU()
        self.conv13 = paddle.nn.Conv2D(weight_attr='conv13.weight', bias_attr='vgg19_Const_27', in_channels=512, out_channels=512, kernel_size=[3, 3], padding='SAME')
        self.relu13 = paddle.nn.ReLU()
        self.conv14 = paddle.nn.Conv2D(weight_attr='conv14.weight', bias_attr=False, in_channels=1475, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.bn0 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_sf_BatchNorm_FusedBatchNorm_g_sf_BatchNorm_Const', bias_attr='g_sf_BatchNorm_FusedBatchNorm_g_sf_BatchNorm_beta', moving_mean_name='g_sf_BatchNorm_FusedBatchNorm_g_sf_BatchNorm_Const_1', moving_variance_name='g_sf_BatchNorm_FusedBatchNorm_g_sf_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.conv15 = paddle.nn.Conv2D(weight_attr='conv15.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.bn1 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_conv0_BatchNorm_FusedBatchNorm_g_conv0_BatchNorm_Const', bias_attr='g_conv0_BatchNorm_FusedBatchNorm_g_conv0_BatchNorm_beta', moving_mean_name='g_conv0_BatchNorm_FusedBatchNorm_g_conv0_BatchNorm_Const_1', moving_variance_name='g_conv0_BatchNorm_FusedBatchNorm_g_conv0_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.conv16 = paddle.nn.Conv2D(weight_attr='conv16.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.bn2 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_conv1_BatchNorm_FusedBatchNorm_g_conv1_BatchNorm_Const', bias_attr='g_conv1_BatchNorm_FusedBatchNorm_g_conv1_BatchNorm_beta', moving_mean_name='g_conv1_BatchNorm_FusedBatchNorm_g_conv1_BatchNorm_Const_1', moving_variance_name='g_conv1_BatchNorm_FusedBatchNorm_g_conv1_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.relu14 = paddle.nn.ReLU()
        self.relu15 = paddle.nn.ReLU()
        self.sigmoid0 = paddle.nn.Sigmoid()
        self.sigmoid1 = paddle.nn.Sigmoid()
        self.conv17 = paddle.nn.Conv2D(weight_attr='conv17.weight', bias_attr=False, in_channels=128, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.conv18 = paddle.nn.Conv2D(weight_attr='conv18.weight', bias_attr=False, in_channels=128, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.bn3 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_aggi_0agg2_BatchNorm_FusedBatchNorm_g_aggi_0agg2_BatchNorm_Const', bias_attr='g_aggi_0agg2_BatchNorm_FusedBatchNorm_g_aggi_0agg2_BatchNorm_beta', moving_mean_name='g_aggi_0agg2_BatchNorm_FusedBatchNorm_g_aggi_0agg2_BatchNorm_Const_1', moving_variance_name='g_aggi_0agg2_BatchNorm_FusedBatchNorm_g_aggi_0agg2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn4 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_aggm_0agg2_BatchNorm_FusedBatchNorm_g_aggm_0agg2_BatchNorm_Const', bias_attr='g_aggm_0agg2_BatchNorm_FusedBatchNorm_g_aggm_0agg2_BatchNorm_beta', moving_mean_name='g_aggm_0agg2_BatchNorm_FusedBatchNorm_g_aggm_0agg2_BatchNorm_Const_1', moving_variance_name='g_aggm_0agg2_BatchNorm_FusedBatchNorm_g_aggm_0agg2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.sigmoid2 = paddle.nn.Sigmoid()
        self.conv19 = paddle.nn.Conv2D(weight_attr='conv19.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[3, 3], padding='VALID')
        self.bn5 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_conv2_BatchNorm_FusedBatchNorm_g_conv2_BatchNorm_Const', bias_attr='g_conv2_BatchNorm_FusedBatchNorm_g_conv2_BatchNorm_beta', moving_mean_name='g_conv2_BatchNorm_FusedBatchNorm_g_conv2_BatchNorm_Const_1', moving_variance_name='g_conv2_BatchNorm_FusedBatchNorm_g_conv2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.conv20 = paddle.nn.Conv2D(weight_attr='conv20.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[3, 3], padding='VALID')
        self.bn6 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_conv3_BatchNorm_FusedBatchNorm_g_conv3_BatchNorm_Const', bias_attr='g_conv3_BatchNorm_FusedBatchNorm_g_conv3_BatchNorm_beta', moving_mean_name='g_conv3_BatchNorm_FusedBatchNorm_g_conv3_BatchNorm_Const_1', moving_variance_name='g_conv3_BatchNorm_FusedBatchNorm_g_conv3_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.relu16 = paddle.nn.ReLU()
        self.relu17 = paddle.nn.ReLU()
        self.sigmoid3 = paddle.nn.Sigmoid()
        self.sigmoid4 = paddle.nn.Sigmoid()
        self.conv21 = paddle.nn.Conv2D(weight_attr='conv21.weight', bias_attr=False, in_channels=192, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.conv22 = paddle.nn.Conv2D(weight_attr='conv22.weight', bias_attr=False, in_channels=192, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.bn7 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_aggi_1agg2_BatchNorm_FusedBatchNorm_g_aggi_1agg2_BatchNorm_Const', bias_attr='g_aggi_1agg2_BatchNorm_FusedBatchNorm_g_aggi_1agg2_BatchNorm_beta', moving_mean_name='g_aggi_1agg2_BatchNorm_FusedBatchNorm_g_aggi_1agg2_BatchNorm_Const_1', moving_variance_name='g_aggi_1agg2_BatchNorm_FusedBatchNorm_g_aggi_1agg2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn8 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_aggm_1agg2_BatchNorm_FusedBatchNorm_g_aggm_1agg2_BatchNorm_Const', bias_attr='g_aggm_1agg2_BatchNorm_FusedBatchNorm_g_aggm_1agg2_BatchNorm_beta', moving_mean_name='g_aggm_1agg2_BatchNorm_FusedBatchNorm_g_aggm_1agg2_BatchNorm_Const_1', moving_variance_name='g_aggm_1agg2_BatchNorm_FusedBatchNorm_g_aggm_1agg2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.sigmoid5 = paddle.nn.Sigmoid()
        self.conv23 = paddle.nn.Conv2D(weight_attr='conv23.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[3, 3], padding='VALID')
        self.bn9 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_conv4_BatchNorm_FusedBatchNorm_g_conv4_BatchNorm_Const', bias_attr='g_conv4_BatchNorm_FusedBatchNorm_g_conv4_BatchNorm_beta', moving_mean_name='g_conv4_BatchNorm_FusedBatchNorm_g_conv4_BatchNorm_Const_1', moving_variance_name='g_conv4_BatchNorm_FusedBatchNorm_g_conv4_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.conv24 = paddle.nn.Conv2D(weight_attr='conv24.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[3, 3], padding='VALID')
        self.bn10 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_conv5_BatchNorm_FusedBatchNorm_g_conv5_BatchNorm_Const', bias_attr='g_conv5_BatchNorm_FusedBatchNorm_g_conv5_BatchNorm_beta', moving_mean_name='g_conv5_BatchNorm_FusedBatchNorm_g_conv5_BatchNorm_Const_1', moving_variance_name='g_conv5_BatchNorm_FusedBatchNorm_g_conv5_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.relu18 = paddle.nn.ReLU()
        self.relu19 = paddle.nn.ReLU()
        self.sigmoid6 = paddle.nn.Sigmoid()
        self.sigmoid7 = paddle.nn.Sigmoid()
        self.conv25 = paddle.nn.Conv2D(weight_attr='conv25.weight', bias_attr=False, in_channels=192, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.conv26 = paddle.nn.Conv2D(weight_attr='conv26.weight', bias_attr=False, in_channels=192, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.bn11 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_aggi_2agg2_BatchNorm_FusedBatchNorm_g_aggi_2agg2_BatchNorm_Const', bias_attr='g_aggi_2agg2_BatchNorm_FusedBatchNorm_g_aggi_2agg2_BatchNorm_beta', moving_mean_name='g_aggi_2agg2_BatchNorm_FusedBatchNorm_g_aggi_2agg2_BatchNorm_Const_1', moving_variance_name='g_aggi_2agg2_BatchNorm_FusedBatchNorm_g_aggi_2agg2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn12 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_aggm_2agg2_BatchNorm_FusedBatchNorm_g_aggm_2agg2_BatchNorm_Const', bias_attr='g_aggm_2agg2_BatchNorm_FusedBatchNorm_g_aggm_2agg2_BatchNorm_beta', moving_mean_name='g_aggm_2agg2_BatchNorm_FusedBatchNorm_g_aggm_2agg2_BatchNorm_Const_1', moving_variance_name='g_aggm_2agg2_BatchNorm_FusedBatchNorm_g_aggm_2agg2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.sigmoid8 = paddle.nn.Sigmoid()
        self.conv27 = paddle.nn.Conv2D(weight_attr='conv27.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[3, 3], padding='VALID')
        self.bn13 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_conv6_BatchNorm_FusedBatchNorm_g_conv6_BatchNorm_Const', bias_attr='g_conv6_BatchNorm_FusedBatchNorm_g_conv6_BatchNorm_beta', moving_mean_name='g_conv6_BatchNorm_FusedBatchNorm_g_conv6_BatchNorm_Const_1', moving_variance_name='g_conv6_BatchNorm_FusedBatchNorm_g_conv6_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.conv28 = paddle.nn.Conv2D(weight_attr='conv28.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[3, 3], padding='VALID')
        self.bn14 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_conv7_BatchNorm_FusedBatchNorm_g_conv7_BatchNorm_Const', bias_attr='g_conv7_BatchNorm_FusedBatchNorm_g_conv7_BatchNorm_beta', moving_mean_name='g_conv7_BatchNorm_FusedBatchNorm_g_conv7_BatchNorm_Const_1', moving_variance_name='g_conv7_BatchNorm_FusedBatchNorm_g_conv7_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.relu20 = paddle.nn.ReLU()
        self.relu21 = paddle.nn.ReLU()
        self.sigmoid9 = paddle.nn.Sigmoid()
        self.sigmoid10 = paddle.nn.Sigmoid()
        self.conv29 = paddle.nn.Conv2D(weight_attr='conv29.weight', bias_attr=False, in_channels=256, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.conv30 = paddle.nn.Conv2D(weight_attr='conv30.weight', bias_attr=False, in_channels=256, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.bn15 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_aggi_3agg2_BatchNorm_FusedBatchNorm_g_aggi_3agg2_BatchNorm_Const', bias_attr='g_aggi_3agg2_BatchNorm_FusedBatchNorm_g_aggi_3agg2_BatchNorm_beta', moving_mean_name='g_aggi_3agg2_BatchNorm_FusedBatchNorm_g_aggi_3agg2_BatchNorm_Const_1', moving_variance_name='g_aggi_3agg2_BatchNorm_FusedBatchNorm_g_aggi_3agg2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn16 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_aggm_3agg2_BatchNorm_FusedBatchNorm_g_aggm_3agg2_BatchNorm_Const', bias_attr='g_aggm_3agg2_BatchNorm_FusedBatchNorm_g_aggm_3agg2_BatchNorm_beta', moving_mean_name='g_aggm_3agg2_BatchNorm_FusedBatchNorm_g_aggm_3agg2_BatchNorm_Const_1', moving_variance_name='g_aggm_3agg2_BatchNorm_FusedBatchNorm_g_aggm_3agg2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.pool4 = paddle.nn.AvgPool2D(kernel_size=[4, 4], stride=4, padding='SAME')
        self.pool5 = paddle.nn.AvgPool2D(kernel_size=[8, 8], stride=8, padding='SAME')
        self.pool6 = paddle.nn.AvgPool2D(kernel_size=[16, 16], stride=16, padding='SAME')
        self.pool7 = paddle.nn.AvgPool2D(kernel_size=[32, 32], stride=32, padding='SAME')
        self.pool8 = paddle.nn.AvgPool2D(kernel_size=[4, 4], stride=4, padding='SAME')
        self.pool9 = paddle.nn.AvgPool2D(kernel_size=[8, 8], stride=8, padding='SAME')
        self.pool10 = paddle.nn.AvgPool2D(kernel_size=[16, 16], stride=16, padding='SAME')
        self.pool11 = paddle.nn.AvgPool2D(kernel_size=[32, 32], stride=32, padding='SAME')
        self.conv31 = paddle.nn.Conv2D(weight_attr='conv31.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.conv32 = paddle.nn.Conv2D(weight_attr='conv32.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.conv33 = paddle.nn.Conv2D(weight_attr='conv33.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.conv34 = paddle.nn.Conv2D(weight_attr='conv34.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.conv35 = paddle.nn.Conv2D(weight_attr='conv35.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.conv36 = paddle.nn.Conv2D(weight_attr='conv36.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.conv37 = paddle.nn.Conv2D(weight_attr='conv37.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.conv38 = paddle.nn.Conv2D(weight_attr='conv38.weight', bias_attr=False, in_channels=64, out_channels=64, kernel_size=[1, 1], padding='SAME')
        self.bn17 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_imgpool2_BatchNorm_FusedBatchNorm_g_imgpool2_BatchNorm_Const', bias_attr='g_imgpool2_BatchNorm_FusedBatchNorm_g_imgpool2_BatchNorm_beta', moving_mean_name='g_imgpool2_BatchNorm_FusedBatchNorm_g_imgpool2_BatchNorm_Const_1', moving_variance_name='g_imgpool2_BatchNorm_FusedBatchNorm_g_imgpool2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn18 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_imgpool8_BatchNorm_FusedBatchNorm_g_imgpool8_BatchNorm_Const', bias_attr='g_imgpool8_BatchNorm_FusedBatchNorm_g_imgpool8_BatchNorm_beta', moving_mean_name='g_imgpool8_BatchNorm_FusedBatchNorm_g_imgpool8_BatchNorm_Const_1', moving_variance_name='g_imgpool8_BatchNorm_FusedBatchNorm_g_imgpool8_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn19 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_imgpool16_BatchNorm_FusedBatchNorm_g_imgpool16_BatchNorm_Const', bias_attr='g_imgpool16_BatchNorm_FusedBatchNorm_g_imgpool16_BatchNorm_beta', moving_mean_name='g_imgpool16_BatchNorm_FusedBatchNorm_g_imgpool16_BatchNorm_Const_1', moving_variance_name='g_imgpool16_BatchNorm_FusedBatchNorm_g_imgpool16_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn20 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_imgpool32_BatchNorm_FusedBatchNorm_g_imgpool32_BatchNorm_Const', bias_attr='g_imgpool32_BatchNorm_FusedBatchNorm_g_imgpool32_BatchNorm_beta', moving_mean_name='g_imgpool32_BatchNorm_FusedBatchNorm_g_imgpool32_BatchNorm_Const_1', moving_variance_name='g_imgpool32_BatchNorm_FusedBatchNorm_g_imgpool32_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn21 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_maskpool2_BatchNorm_FusedBatchNorm_g_maskpool2_BatchNorm_Const', bias_attr='g_maskpool2_BatchNorm_FusedBatchNorm_g_maskpool2_BatchNorm_beta', moving_mean_name='g_maskpool2_BatchNorm_FusedBatchNorm_g_maskpool2_BatchNorm_Const_1', moving_variance_name='g_maskpool2_BatchNorm_FusedBatchNorm_g_maskpool2_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn22 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_maskpool8_BatchNorm_FusedBatchNorm_g_maskpool8_BatchNorm_Const', bias_attr='g_maskpool8_BatchNorm_FusedBatchNorm_g_maskpool8_BatchNorm_beta', moving_mean_name='g_maskpool8_BatchNorm_FusedBatchNorm_g_maskpool8_BatchNorm_Const_1', moving_variance_name='g_maskpool8_BatchNorm_FusedBatchNorm_g_maskpool8_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn23 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_maskpool16_BatchNorm_FusedBatchNorm_g_maskpool16_BatchNorm_Const', bias_attr='g_maskpool16_BatchNorm_FusedBatchNorm_g_maskpool16_BatchNorm_beta', moving_mean_name='g_maskpool16_BatchNorm_FusedBatchNorm_g_maskpool16_BatchNorm_Const_1', moving_variance_name='g_maskpool16_BatchNorm_FusedBatchNorm_g_maskpool16_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn24 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_maskpool32_BatchNorm_FusedBatchNorm_g_maskpool32_BatchNorm_Const', bias_attr='g_maskpool32_BatchNorm_FusedBatchNorm_g_maskpool32_BatchNorm_beta', moving_mean_name='g_maskpool32_BatchNorm_FusedBatchNorm_g_maskpool32_BatchNorm_Const_1', moving_variance_name='g_maskpool32_BatchNorm_FusedBatchNorm_g_maskpool32_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.conv39 = paddle.nn.Conv2D(weight_attr='conv39.weight', bias_attr=False, in_channels=320, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.conv40 = paddle.nn.Conv2D(weight_attr='conv40.weight', bias_attr=False, in_channels=320, out_channels=64, kernel_size=[3, 3], padding='SAME')
        self.bn25 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_imgpoolsf_BatchNorm_FusedBatchNorm_g_imgpoolsf_BatchNorm_Const', bias_attr='g_imgpoolsf_BatchNorm_FusedBatchNorm_g_imgpoolsf_BatchNorm_beta', moving_mean_name='g_imgpoolsf_BatchNorm_FusedBatchNorm_g_imgpoolsf_BatchNorm_Const_1', moving_variance_name='g_imgpoolsf_BatchNorm_FusedBatchNorm_g_imgpoolsf_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.bn26 = paddle.nn.BatchNorm(num_channels=64, epsilon=0.0010000000474974513, param_attr='g_maskpoolsf_BatchNorm_FusedBatchNorm_g_maskpoolsf_BatchNorm_Const', bias_attr='g_maskpoolsf_BatchNorm_FusedBatchNorm_g_maskpoolsf_BatchNorm_beta', moving_mean_name='g_maskpoolsf_BatchNorm_FusedBatchNorm_g_maskpoolsf_BatchNorm_Const_1', moving_variance_name='g_maskpoolsf_BatchNorm_FusedBatchNorm_g_maskpoolsf_BatchNorm_Const_2', is_test=True, trainable_statistics=True)
        self.sigmoid11 = paddle.nn.Sigmoid()
        self.conv41 = paddle.nn.Conv2D(weight_attr='conv41.weight', bias_attr='g_conv_mask_biases', in_channels=64, out_channels=1, kernel_size=[1, 1], padding='SAME')
        self.conv42 = paddle.nn.Conv2D(weight_attr='conv42.weight', bias_attr='g_conv_img_biases', in_channels=64, out_channels=3, kernel_size=[1, 1], padding='SAME')

    def forward(self, Placeholder):
        mul_y = paddle.full(dtype='float32', shape=[1], fill_value=255.0)
        vgg19_sub_y = self.vgg19_sub_y
        Shape = self.Shape
        Shape_1 = self.Shape_1
        truediv_y = paddle.full(dtype='float32', shape=[1], fill_value=255.0)
        Shape_2 = self.Shape_2
        Shape_3 = self.Shape_3
        truediv_1_y = paddle.full(dtype='float32', shape=[1], fill_value=255.0)
        Shape_4 = self.Shape_4
        Shape_5 = self.Shape_5
        truediv_2_y = paddle.full(dtype='float32', shape=[1], fill_value=255.0)
        Shape_6 = self.Shape_6
        Shape_7 = self.Shape_7
        truediv_3_y = paddle.full(dtype='float32', shape=[1], fill_value=255.0)
        Shape_8 = self.Shape_8
        Shape_9 = self.Shape_9
        truediv_4_y = paddle.full(dtype='float32', shape=[1], fill_value=255.0)
        g_sf_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.8586508631706238)
        g_sf_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.1150323674082756)
        g_sf_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_conv0_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.8726819157600403)
        g_conv0_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.10762055963277817)
        g_conv0_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_conv1_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.7213011980056763)
        g_conv1_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.09084192663431168)
        g_conv1_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_aggi_0att2_bottleneck_fc_kernel = self.g_aggi_0att2_bottleneck_fc_kernel
        g_aggi_0att2_bottleneck_fc_bias = self.g_aggi_0att2_bottleneck_fc_bias
        g_aggi_0att2_recover_fc_kernel = self.g_aggi_0att2_recover_fc_kernel
        g_aggi_0att2_recover_fc_bias = self.g_aggi_0att2_recover_fc_bias
        g_aggi_0agg2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.8595666289329529)
        g_aggi_0agg2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.05452089011669159)
        g_aggi_0agg2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_aggm_0att2_bottleneck_fc_kernel = self.g_aggm_0att2_bottleneck_fc_kernel
        g_aggm_0att2_bottleneck_fc_bias = self.g_aggm_0att2_bottleneck_fc_bias
        g_aggm_0att2_recover_fc_kernel = self.g_aggm_0att2_recover_fc_kernel
        g_aggm_0att2_recover_fc_bias = self.g_aggm_0att2_recover_fc_bias
        g_aggm_0agg2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9285162687301636)
        g_aggm_0agg2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.049991823732852936)
        g_aggm_0agg2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_conv2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.39222222566604614)
        g_conv2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.22528040409088135)
        g_conv2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_conv3_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.5128512978553772)
        g_conv3_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.26698705554008484)
        g_conv3_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_aggi_1att2_bottleneck_fc_kernel = self.g_aggi_1att2_bottleneck_fc_kernel
        g_aggi_1att2_bottleneck_fc_bias = self.g_aggi_1att2_bottleneck_fc_bias
        g_aggi_1att2_recover_fc_kernel = self.g_aggi_1att2_recover_fc_kernel
        g_aggi_1att2_recover_fc_bias = self.g_aggi_1att2_recover_fc_bias
        g_aggi_1agg2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.8684962391853333)
        g_aggi_1agg2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.089026540517807)
        g_aggi_1agg2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_aggm_1att2_bottleneck_fc_kernel = self.g_aggm_1att2_bottleneck_fc_kernel
        g_aggm_1att2_bottleneck_fc_bias = self.g_aggm_1att2_bottleneck_fc_bias
        g_aggm_1att2_recover_fc_kernel = self.g_aggm_1att2_recover_fc_kernel
        g_aggm_1att2_recover_fc_bias = self.g_aggm_1att2_recover_fc_bias
        g_aggm_1agg2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=1.0718040466308594)
        g_aggm_1agg2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.24762623012065887)
        g_aggm_1agg2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_conv4_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.5259748697280884)
        g_conv4_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.16369833052158356)
        g_conv4_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_conv5_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.6560022234916687)
        g_conv5_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.18437787890434265)
        g_conv5_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_aggi_2att2_bottleneck_fc_kernel = self.g_aggi_2att2_bottleneck_fc_kernel
        g_aggi_2att2_bottleneck_fc_bias = self.g_aggi_2att2_bottleneck_fc_bias
        g_aggi_2att2_recover_fc_kernel = self.g_aggi_2att2_recover_fc_kernel
        g_aggi_2att2_recover_fc_bias = self.g_aggi_2att2_recover_fc_bias
        g_aggi_2agg2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.7395250797271729)
        g_aggi_2agg2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.03735147789120674)
        g_aggi_2agg2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_aggm_2att2_bottleneck_fc_kernel = self.g_aggm_2att2_bottleneck_fc_kernel
        g_aggm_2att2_bottleneck_fc_bias = self.g_aggm_2att2_bottleneck_fc_bias
        g_aggm_2att2_recover_fc_kernel = self.g_aggm_2att2_recover_fc_kernel
        g_aggm_2att2_recover_fc_bias = self.g_aggm_2att2_recover_fc_bias
        g_aggm_2agg2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=1.2052185535430908)
        g_aggm_2agg2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.23498426377773285)
        g_aggm_2agg2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_conv6_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9189202785491943)
        g_conv6_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.023168113082647324)
        g_conv6_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_conv7_w0 = paddle.full(dtype='float32', shape=[1], fill_value=1.0340877771377563)
        g_conv7_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.07615398615598679)
        g_conv7_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_aggi_3att2_bottleneck_fc_kernel = self.g_aggi_3att2_bottleneck_fc_kernel
        g_aggi_3att2_bottleneck_fc_bias = self.g_aggi_3att2_bottleneck_fc_bias
        g_aggi_3att2_recover_fc_kernel = self.g_aggi_3att2_recover_fc_kernel
        g_aggi_3att2_recover_fc_bias = self.g_aggi_3att2_recover_fc_bias
        g_aggi_3agg2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9676072597503662)
        g_aggi_3agg2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.04219917580485344)
        g_aggi_3agg2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_aggm_3att2_bottleneck_fc_kernel = self.g_aggm_3att2_bottleneck_fc_kernel
        g_aggm_3att2_bottleneck_fc_bias = self.g_aggm_3att2_bottleneck_fc_bias
        g_aggm_3att2_recover_fc_kernel = self.g_aggm_3att2_recover_fc_kernel
        g_aggm_3att2_recover_fc_bias = self.g_aggm_3att2_recover_fc_bias
        g_aggm_3agg2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9483015537261963)
        g_aggm_3agg2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.11270325630903244)
        g_aggm_3agg2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_imgpool2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9920924305915833)
        g_imgpool2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.04413551092147827)
        g_imgpool2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_imgpool8_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9651920795440674)
        g_imgpool8_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.025955921038985252)
        g_imgpool8_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_imgpool16_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9692366719245911)
        g_imgpool16_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.031960971653461456)
        g_imgpool16_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_imgpool32_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9715426564216614)
        g_imgpool32_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.03134226053953171)
        g_imgpool32_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        Shape_10 = self.Shape_10
        Shape_11 = self.Shape_11
        Shape_12 = self.Shape_12
        Shape_13 = self.Shape_13
        Shape_14 = self.Shape_14
        Shape_15 = self.Shape_15
        Shape_16 = self.Shape_16
        Shape_17 = self.Shape_17
        g_imgpoolsf_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9685955047607422)
        g_imgpoolsf_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.0020705671049654484)
        g_imgpoolsf_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_maskpool2_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9997272491455078)
        g_maskpool2_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.08255364745855331)
        g_maskpool2_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_maskpool8_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.8151741027832031)
        g_maskpool8_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.11888425797224045)
        g_maskpool8_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_maskpool16_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9001412987709045)
        g_maskpool16_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.014757533557713032)
        g_maskpool16_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        g_maskpool32_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9132266640663147)
        g_maskpool32_w1 = paddle.full(dtype='float32', shape=[1], fill_value=-0.07348763942718506)
        g_maskpool32_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        Shape_18 = self.Shape_18
        Shape_19 = self.Shape_19
        Shape_20 = self.Shape_20
        Shape_21 = self.Shape_21
        Shape_22 = self.Shape_22
        Shape_23 = self.Shape_23
        Shape_24 = self.Shape_24
        Shape_25 = self.Shape_25
        g_maskpoolsf_w0 = paddle.full(dtype='float32', shape=[1], fill_value=0.9417956471443176)
        g_maskpoolsf_w1 = paddle.full(dtype='float32', shape=[1], fill_value=0.0898890495300293)
        g_maskpoolsf_mul_2_y = paddle.full(dtype='float32', shape=[1], fill_value=0.20000000298023224)
        strided_slice = paddle.slice(input=Placeholder, axes=[0, 1, 2, 3], starts=[0, 0, 0, 0], ends=[999999, 999999, 999999, 3])
        strided_slice_1 = paddle.slice(input=Shape, axes=[0], starts=[1], ends=[2])
        strided_slice_2 = paddle.slice(input=Shape_1, axes=[0], starts=[2], ends=[3])
        strided_slice_3 = paddle.slice(input=Shape_2, axes=[0], starts=[1], ends=[2])
        strided_slice_4 = paddle.slice(input=Shape_3, axes=[0], starts=[2], ends=[3])
        strided_slice_5 = paddle.slice(input=Shape_4, axes=[0], starts=[1], ends=[2])
        strided_slice_6 = paddle.slice(input=Shape_5, axes=[0], starts=[2], ends=[3])
        strided_slice_7 = paddle.slice(input=Shape_6, axes=[0], starts=[1], ends=[2])
        strided_slice_8 = paddle.slice(input=Shape_7, axes=[0], starts=[2], ends=[3])
        strided_slice_9 = paddle.slice(input=Shape_8, axes=[0], starts=[1], ends=[2])
        strided_slice_10 = paddle.slice(input=Shape_9, axes=[0], starts=[2], ends=[3])
        strided_slice_11 = paddle.slice(input=Shape_10, axes=[0], starts=[1], ends=[2])
        strided_slice_12 = paddle.slice(input=Shape_11, axes=[0], starts=[2], ends=[3])
        strided_slice_13 = paddle.slice(input=Shape_12, axes=[0], starts=[1], ends=[2])
        strided_slice_14 = paddle.slice(input=Shape_13, axes=[0], starts=[2], ends=[3])
        strided_slice_15 = paddle.slice(input=Shape_14, axes=[0], starts=[1], ends=[2])
        strided_slice_16 = paddle.slice(input=Shape_15, axes=[0], starts=[2], ends=[3])
        strided_slice_17 = paddle.slice(input=Shape_16, axes=[0], starts=[1], ends=[2])
        strided_slice_18 = paddle.slice(input=Shape_17, axes=[0], starts=[2], ends=[3])
        strided_slice_19 = paddle.slice(input=Shape_18, axes=[0], starts=[1], ends=[2])
        strided_slice_20 = paddle.slice(input=Shape_19, axes=[0], starts=[2], ends=[3])
        strided_slice_21 = paddle.slice(input=Shape_20, axes=[0], starts=[1], ends=[2])
        strided_slice_22 = paddle.slice(input=Shape_21, axes=[0], starts=[2], ends=[3])
        strided_slice_23 = paddle.slice(input=Shape_22, axes=[0], starts=[1], ends=[2])
        strided_slice_24 = paddle.slice(input=Shape_23, axes=[0], starts=[2], ends=[3])
        strided_slice_25 = paddle.slice(input=Shape_24, axes=[0], starts=[1], ends=[2])
        strided_slice_26 = paddle.slice(input=Shape_25, axes=[0], starts=[2], ends=[3])
        mul = paddle.multiply(x=strided_slice, y=mul_y)
        ResizeBilinear_size = paddle.stack(x=[strided_slice_1, strided_slice_2])
        ResizeBilinear_size = paddle.reshape(x=ResizeBilinear_size, shape=[-1])
        ResizeBilinear_1_size = paddle.stack(x=[strided_slice_3, strided_slice_4])
        ResizeBilinear_1_size = paddle.reshape(x=ResizeBilinear_1_size, shape=[-1])
        ResizeBilinear_2_size = paddle.stack(x=[strided_slice_5, strided_slice_6])
        ResizeBilinear_2_size = paddle.reshape(x=ResizeBilinear_2_size, shape=[-1])
        ResizeBilinear_3_size = paddle.stack(x=[strided_slice_7, strided_slice_8])
        ResizeBilinear_3_size = paddle.reshape(x=ResizeBilinear_3_size, shape=[-1])
        ResizeBilinear_4_size = paddle.stack(x=[strided_slice_9, strided_slice_10])
        ResizeBilinear_4_size = paddle.reshape(x=ResizeBilinear_4_size, shape=[-1])
        g_aggi_0att2_bottleneck_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggi_0att2_bottleneck_fc_kernel, perm=[0, 1])
        g_aggi_0att2_recover_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggi_0att2_recover_fc_kernel, perm=[0, 1])
        g_aggm_0att2_bottleneck_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggm_0att2_bottleneck_fc_kernel, perm=[0, 1])
        g_aggm_0att2_recover_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggm_0att2_recover_fc_kernel, perm=[0, 1])
        g_aggi_1att2_bottleneck_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggi_1att2_bottleneck_fc_kernel, perm=[0, 1])
        g_aggi_1att2_recover_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggi_1att2_recover_fc_kernel, perm=[0, 1])
        g_aggm_1att2_bottleneck_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggm_1att2_bottleneck_fc_kernel, perm=[0, 1])
        g_aggm_1att2_recover_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggm_1att2_recover_fc_kernel, perm=[0, 1])
        g_aggi_2att2_bottleneck_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggi_2att2_bottleneck_fc_kernel, perm=[0, 1])
        g_aggi_2att2_recover_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggi_2att2_recover_fc_kernel, perm=[0, 1])
        g_aggm_2att2_bottleneck_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggm_2att2_bottleneck_fc_kernel, perm=[0, 1])
        g_aggm_2att2_recover_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggm_2att2_recover_fc_kernel, perm=[0, 1])
        g_aggi_3att2_bottleneck_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggi_3att2_bottleneck_fc_kernel, perm=[0, 1])
        g_aggi_3att2_recover_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggi_3att2_recover_fc_kernel, perm=[0, 1])
        g_aggm_3att2_bottleneck_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggm_3att2_bottleneck_fc_kernel, perm=[0, 1])
        g_aggm_3att2_recover_fc_Tensordot_transpose_1 = paddle.transpose(x=g_aggm_3att2_recover_fc_kernel, perm=[0, 1])
        ResizeBilinear_5_size = paddle.stack(x=[strided_slice_11, strided_slice_12])
        ResizeBilinear_5_size = paddle.reshape(x=ResizeBilinear_5_size, shape=[-1])
        ResizeBilinear_6_size = paddle.stack(x=[strided_slice_13, strided_slice_14])
        ResizeBilinear_6_size = paddle.reshape(x=ResizeBilinear_6_size, shape=[-1])
        ResizeBilinear_7_size = paddle.stack(x=[strided_slice_15, strided_slice_16])
        ResizeBilinear_7_size = paddle.reshape(x=ResizeBilinear_7_size, shape=[-1])
        ResizeBilinear_8_size = paddle.stack(x=[strided_slice_17, strided_slice_18])
        ResizeBilinear_8_size = paddle.reshape(x=ResizeBilinear_8_size, shape=[-1])
        ResizeBilinear_9_size = paddle.stack(x=[strided_slice_19, strided_slice_20])
        ResizeBilinear_9_size = paddle.reshape(x=ResizeBilinear_9_size, shape=[-1])
        ResizeBilinear_10_size = paddle.stack(x=[strided_slice_21, strided_slice_22])
        ResizeBilinear_10_size = paddle.reshape(x=ResizeBilinear_10_size, shape=[-1])
        ResizeBilinear_11_size = paddle.stack(x=[strided_slice_23, strided_slice_24])
        ResizeBilinear_11_size = paddle.reshape(x=ResizeBilinear_11_size, shape=[-1])
        ResizeBilinear_12_size = paddle.stack(x=[strided_slice_25, strided_slice_26])
        ResizeBilinear_12_size = paddle.reshape(x=ResizeBilinear_12_size, shape=[-1])
        vgg19_sub = paddle.subtract(x=mul, y=vgg19_sub_y)
        g_aggi_0att2_bottleneck_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggi_0att2_bottleneck_fc_Tensordot_transpose_1, shape=[128, 16])
        g_aggi_0att2_recover_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggi_0att2_recover_fc_Tensordot_transpose_1, shape=[16, 128])
        g_aggm_0att2_bottleneck_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggm_0att2_bottleneck_fc_Tensordot_transpose_1, shape=[128, 16])
        g_aggm_0att2_recover_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggm_0att2_recover_fc_Tensordot_transpose_1, shape=[16, 128])
        g_aggi_1att2_bottleneck_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggi_1att2_bottleneck_fc_Tensordot_transpose_1, shape=[192, 24])
        g_aggi_1att2_recover_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggi_1att2_recover_fc_Tensordot_transpose_1, shape=[24, 192])
        g_aggm_1att2_bottleneck_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggm_1att2_bottleneck_fc_Tensordot_transpose_1, shape=[192, 24])
        g_aggm_1att2_recover_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggm_1att2_recover_fc_Tensordot_transpose_1, shape=[24, 192])
        g_aggi_2att2_bottleneck_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggi_2att2_bottleneck_fc_Tensordot_transpose_1, shape=[192, 24])
        g_aggi_2att2_recover_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggi_2att2_recover_fc_Tensordot_transpose_1, shape=[24, 192])
        g_aggm_2att2_bottleneck_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggm_2att2_bottleneck_fc_Tensordot_transpose_1, shape=[192, 24])
        g_aggm_2att2_recover_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggm_2att2_recover_fc_Tensordot_transpose_1, shape=[24, 192])
        g_aggi_3att2_bottleneck_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggi_3att2_bottleneck_fc_Tensordot_transpose_1, shape=[256, 32])
        g_aggi_3att2_recover_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggi_3att2_recover_fc_Tensordot_transpose_1, shape=[32, 256])
        g_aggm_3att2_bottleneck_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggm_3att2_bottleneck_fc_Tensordot_transpose_1, shape=[256, 32])
        g_aggm_3att2_recover_fc_Tensordot_Reshape_1 = paddle.reshape(x=g_aggm_3att2_recover_fc_Tensordot_transpose_1, shape=[32, 256])
        conv2d_transpose_0 = paddle.transpose(x=vgg19_sub, perm=[0, 3, 1, 2])
        vgg19_vgg_conv1_1 = self.conv0(conv2d_transpose_0)
        vgg19_Relu = self.relu0(vgg19_vgg_conv1_1)
        vgg19_vgg_conv1_2 = self.conv1(vgg19_Relu)
        vgg19_Relu_1 = self.relu1(vgg19_vgg_conv1_2)
        vgg19_AvgPool = self.pool0(vgg19_Relu_1)
        resize_bilinear_reshape_0 = paddle.reshape(x=ResizeBilinear_size, shape=[2])
        ResizeBilinear = paddle.nn.functional.interpolate(x=vgg19_Relu_1, size=resize_bilinear_reshape_0, mode='bilinear', align_mode=1)
        ResizeBilinear = paddle.transpose(x=ResizeBilinear, perm=[0, 2, 3, 1])
        vgg19_vgg_conv2_1 = self.conv2(vgg19_AvgPool)
        truediv = paddle.divide(x=ResizeBilinear, y=truediv_y)
        concat = paddle.concat(x=[truediv, Placeholder], axis=3)
        vgg19_Relu_2 = self.relu2(vgg19_vgg_conv2_1)
        vgg19_vgg_conv2_2 = self.conv3(vgg19_Relu_2)
        vgg19_Relu_3 = self.relu3(vgg19_vgg_conv2_2)
        vgg19_AvgPool_1 = self.pool1(vgg19_Relu_3)
        resize_bilinear_reshape_2 = paddle.reshape(x=ResizeBilinear_1_size, shape=[2])
        ResizeBilinear_1 = paddle.nn.functional.interpolate(x=vgg19_Relu_3, size=resize_bilinear_reshape_2, mode='bilinear', align_mode=1)
        ResizeBilinear_1 = paddle.transpose(x=ResizeBilinear_1, perm=[0, 2, 3, 1])
        vgg19_vgg_conv3_1 = self.conv4(vgg19_AvgPool_1)
        truediv_1 = paddle.divide(x=ResizeBilinear_1, y=truediv_1_y)
        concat_1 = paddle.concat(x=[truediv_1, concat], axis=3)
        vgg19_Relu_4 = self.relu4(vgg19_vgg_conv3_1)
        vgg19_vgg_conv3_2 = self.conv5(vgg19_Relu_4)
        vgg19_Relu_5 = self.relu5(vgg19_vgg_conv3_2)
        vgg19_vgg_conv3_3 = self.conv6(vgg19_Relu_5)
        resize_bilinear_reshape_4 = paddle.reshape(x=ResizeBilinear_2_size, shape=[2])
        ResizeBilinear_2 = paddle.nn.functional.interpolate(x=vgg19_Relu_5, size=resize_bilinear_reshape_4, mode='bilinear', align_mode=1)
        ResizeBilinear_2 = paddle.transpose(x=ResizeBilinear_2, perm=[0, 2, 3, 1])
        truediv_2 = paddle.divide(x=ResizeBilinear_2, y=truediv_2_y)
        vgg19_Relu_6 = self.relu6(vgg19_vgg_conv3_3)
        concat_2 = paddle.concat(x=[truediv_2, concat_1], axis=3)
        vgg19_vgg_conv3_4 = self.conv7(vgg19_Relu_6)
        vgg19_Relu_7 = self.relu7(vgg19_vgg_conv3_4)
        vgg19_AvgPool_2 = self.pool2(vgg19_Relu_7)
        vgg19_vgg_conv4_1 = self.conv8(vgg19_AvgPool_2)
        vgg19_Relu_8 = self.relu8(vgg19_vgg_conv4_1)
        vgg19_vgg_conv4_2 = self.conv9(vgg19_Relu_8)
        vgg19_Relu_9 = self.relu9(vgg19_vgg_conv4_2)
        vgg19_vgg_conv4_3 = self.conv10(vgg19_Relu_9)
        resize_bilinear_reshape_6 = paddle.reshape(x=ResizeBilinear_3_size, shape=[2])
        ResizeBilinear_3 = paddle.nn.functional.interpolate(x=vgg19_Relu_9, size=resize_bilinear_reshape_6, mode='bilinear', align_mode=1)
        ResizeBilinear_3 = paddle.transpose(x=ResizeBilinear_3, perm=[0, 2, 3, 1])
        truediv_3 = paddle.divide(x=ResizeBilinear_3, y=truediv_3_y)
        vgg19_Relu_10 = self.relu10(vgg19_vgg_conv4_3)
        concat_3 = paddle.concat(x=[truediv_3, concat_2], axis=3)
        vgg19_vgg_conv4_4 = self.conv11(vgg19_Relu_10)
        vgg19_Relu_11 = self.relu11(vgg19_vgg_conv4_4)
        vgg19_AvgPool_3 = self.pool3(vgg19_Relu_11)
        vgg19_vgg_conv5_1 = self.conv12(vgg19_AvgPool_3)
        vgg19_Relu_12 = self.relu12(vgg19_vgg_conv5_1)
        vgg19_vgg_conv5_2 = self.conv13(vgg19_Relu_12)
        vgg19_Relu_13 = self.relu13(vgg19_vgg_conv5_2)
        resize_bilinear_reshape_8 = paddle.reshape(x=ResizeBilinear_4_size, shape=[2])
        ResizeBilinear_4 = paddle.nn.functional.interpolate(x=vgg19_Relu_13, size=resize_bilinear_reshape_8, mode='bilinear', align_mode=1)
        ResizeBilinear_4 = paddle.transpose(x=ResizeBilinear_4, perm=[0, 2, 3, 1])
        truediv_4 = paddle.divide(x=ResizeBilinear_4, y=truediv_4_y)
        concat_4 = paddle.concat(x=[truediv_4, concat_3], axis=3)
        conv2d_transpose_14 = paddle.transpose(x=concat_4, perm=[0, 3, 1, 2])
        g_sf_Conv2D = self.conv14(conv2d_transpose_14)
        g_sf_Conv2D = paddle.transpose(x=g_sf_Conv2D, perm=[0, 2, 3, 1])
        g_sf_mul = paddle.multiply(x=g_sf_w0, y=g_sf_Conv2D)
        batch_norm_transpose_0 = paddle.transpose(x=g_sf_Conv2D, perm=[0, 3, 1, 2])
        g_sf_BatchNorm_FusedBatchNorm = self.bn0(batch_norm_transpose_0)
        g_sf_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_sf_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_sf_mul_1 = paddle.multiply(x=g_sf_w1, y=g_sf_BatchNorm_FusedBatchNorm)
        g_sf_add = paddle.add(x=g_sf_mul, y=g_sf_mul_1)
        g_sf_mul_2 = paddle.multiply(x=g_sf_add, y=g_sf_mul_2_y)
        g_sf_Maximum = paddle.maximum(x=g_sf_mul_2, y=g_sf_add)
        conv2d_transpose_15 = paddle.transpose(x=g_sf_Maximum, perm=[0, 3, 1, 2])
        g_conv0_Conv2D = self.conv15(conv2d_transpose_15)
        g_conv0_Conv2D = paddle.transpose(x=g_conv0_Conv2D, perm=[0, 2, 3, 1])
        g_conv0_mul = paddle.multiply(x=g_conv0_w0, y=g_conv0_Conv2D)
        batch_norm_transpose_1 = paddle.transpose(x=g_conv0_Conv2D, perm=[0, 3, 1, 2])
        g_conv0_BatchNorm_FusedBatchNorm = self.bn1(batch_norm_transpose_1)
        g_conv0_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_conv0_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_conv0_mul_1 = paddle.multiply(x=g_conv0_w1, y=g_conv0_BatchNorm_FusedBatchNorm)
        g_conv0_add = paddle.add(x=g_conv0_mul, y=g_conv0_mul_1)
        g_conv0_mul_2 = paddle.multiply(x=g_conv0_add, y=g_conv0_mul_2_y)
        g_conv0_Maximum = paddle.maximum(x=g_conv0_mul_2, y=g_conv0_add)
        conv2d_transpose_16 = paddle.transpose(x=g_conv0_Maximum, perm=[0, 3, 1, 2])
        g_conv1_Conv2D = self.conv16(conv2d_transpose_16)
        g_conv1_Conv2D = paddle.transpose(x=g_conv1_Conv2D, perm=[0, 2, 3, 1])
        g_conv1_mul = paddle.multiply(x=g_conv1_w0, y=g_conv1_Conv2D)
        batch_norm_transpose_2 = paddle.transpose(x=g_conv1_Conv2D, perm=[0, 3, 1, 2])
        g_conv1_BatchNorm_FusedBatchNorm = self.bn2(batch_norm_transpose_2)
        g_conv1_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_conv1_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_conv1_mul_1 = paddle.multiply(x=g_conv1_w1, y=g_conv1_BatchNorm_FusedBatchNorm)
        g_conv1_add = paddle.add(x=g_conv1_mul, y=g_conv1_mul_1)
        g_conv1_mul_2 = paddle.multiply(x=g_conv1_add, y=g_conv1_mul_2_y)
        g_conv1_Maximum = paddle.maximum(x=g_conv1_mul_2, y=g_conv1_add)
        concat_5 = paddle.concat(x=[g_conv0_Maximum, g_conv1_Maximum], axis=3)
        g_aggi_0att2_Mean = paddle.mean(x=concat_5, axis=[1, 2], keepdim=True)
        g_aggm_0att2_Mean = paddle.mean(x=concat_5, axis=[1, 2], keepdim=True)
        g_aggi_0att2_bottleneck_fc_Tensordot_transpose = paddle.transpose(x=g_aggi_0att2_Mean, perm=[0, 1, 2, 3])
        g_aggm_0att2_bottleneck_fc_Tensordot_transpose = paddle.transpose(x=g_aggm_0att2_Mean, perm=[0, 1, 2, 3])
        g_aggi_0att2_bottleneck_fc_Tensordot_Reshape = paddle.reshape(x=g_aggi_0att2_bottleneck_fc_Tensordot_transpose, shape=[1, 128])
        g_aggm_0att2_bottleneck_fc_Tensordot_Reshape = paddle.reshape(x=g_aggm_0att2_bottleneck_fc_Tensordot_transpose, shape=[1, 128])
        g_aggi_0att2_bottleneck_fc_Tensordot_MatMul = paddle.matmul(x=g_aggi_0att2_bottleneck_fc_Tensordot_Reshape, y=g_aggi_0att2_bottleneck_fc_Tensordot_Reshape_1)
        g_aggm_0att2_bottleneck_fc_Tensordot_MatMul = paddle.matmul(x=g_aggm_0att2_bottleneck_fc_Tensordot_Reshape, y=g_aggm_0att2_bottleneck_fc_Tensordot_Reshape_1)
        g_aggi_0att2_bottleneck_fc_Tensordot = paddle.reshape(x=g_aggi_0att2_bottleneck_fc_Tensordot_MatMul, shape=[1, 1, 1, 16])
        g_aggm_0att2_bottleneck_fc_Tensordot = paddle.reshape(x=g_aggm_0att2_bottleneck_fc_Tensordot_MatMul, shape=[1, 1, 1, 16])
        g_aggi_0att2_bottleneck_fc_BiasAdd = paddle.add(x=g_aggi_0att2_bottleneck_fc_Tensordot, y=g_aggi_0att2_bottleneck_fc_bias)
        g_aggm_0att2_bottleneck_fc_BiasAdd = paddle.add(x=g_aggm_0att2_bottleneck_fc_Tensordot, y=g_aggm_0att2_bottleneck_fc_bias)
        g_aggi_0att2_bottleneck_fc_Relu = self.relu14(g_aggi_0att2_bottleneck_fc_BiasAdd)
        g_aggm_0att2_bottleneck_fc_Relu = self.relu15(g_aggm_0att2_bottleneck_fc_BiasAdd)
        g_aggi_0att2_recover_fc_Tensordot_transpose = paddle.transpose(x=g_aggi_0att2_bottleneck_fc_Relu, perm=[0, 1, 2, 3])
        g_aggm_0att2_recover_fc_Tensordot_transpose = paddle.transpose(x=g_aggm_0att2_bottleneck_fc_Relu, perm=[0, 1, 2, 3])
        g_aggi_0att2_recover_fc_Tensordot_Reshape = paddle.reshape(x=g_aggi_0att2_recover_fc_Tensordot_transpose, shape=[1, 16])
        g_aggm_0att2_recover_fc_Tensordot_Reshape = paddle.reshape(x=g_aggm_0att2_recover_fc_Tensordot_transpose, shape=[1, 16])
        g_aggi_0att2_recover_fc_Tensordot_MatMul = paddle.matmul(x=g_aggi_0att2_recover_fc_Tensordot_Reshape, y=g_aggi_0att2_recover_fc_Tensordot_Reshape_1)
        g_aggm_0att2_recover_fc_Tensordot_MatMul = paddle.matmul(x=g_aggm_0att2_recover_fc_Tensordot_Reshape, y=g_aggm_0att2_recover_fc_Tensordot_Reshape_1)
        g_aggi_0att2_recover_fc_Tensordot = paddle.reshape(x=g_aggi_0att2_recover_fc_Tensordot_MatMul, shape=[1, 1, 1, 128])
        g_aggm_0att2_recover_fc_Tensordot = paddle.reshape(x=g_aggm_0att2_recover_fc_Tensordot_MatMul, shape=[1, 1, 1, 128])
        g_aggi_0att2_recover_fc_BiasAdd = paddle.add(x=g_aggi_0att2_recover_fc_Tensordot, y=g_aggi_0att2_recover_fc_bias)
        g_aggm_0att2_recover_fc_BiasAdd = paddle.add(x=g_aggm_0att2_recover_fc_Tensordot, y=g_aggm_0att2_recover_fc_bias)
        g_aggi_0att2_recover_fc_Sigmoid = self.sigmoid0(g_aggi_0att2_recover_fc_BiasAdd)
        g_aggm_0att2_recover_fc_Sigmoid = self.sigmoid1(g_aggm_0att2_recover_fc_BiasAdd)
        g_aggi_0att2_mul = paddle.multiply(x=concat_5, y=g_aggi_0att2_recover_fc_Sigmoid)
        g_aggm_0att2_mul = paddle.multiply(x=concat_5, y=g_aggm_0att2_recover_fc_Sigmoid)
        conv2d_transpose_17 = paddle.transpose(x=g_aggi_0att2_mul, perm=[0, 3, 1, 2])
        g_aggi_0agg2_Conv2D = self.conv17(conv2d_transpose_17)
        g_aggi_0agg2_Conv2D = paddle.transpose(x=g_aggi_0agg2_Conv2D, perm=[0, 2, 3, 1])
        conv2d_transpose_18 = paddle.transpose(x=g_aggm_0att2_mul, perm=[0, 3, 1, 2])
        g_aggm_0agg2_Conv2D = self.conv18(conv2d_transpose_18)
        g_aggm_0agg2_Conv2D = paddle.transpose(x=g_aggm_0agg2_Conv2D, perm=[0, 2, 3, 1])
        g_aggi_0agg2_mul = paddle.multiply(x=g_aggi_0agg2_w0, y=g_aggi_0agg2_Conv2D)
        batch_norm_transpose_3 = paddle.transpose(x=g_aggi_0agg2_Conv2D, perm=[0, 3, 1, 2])
        g_aggi_0agg2_BatchNorm_FusedBatchNorm = self.bn3(batch_norm_transpose_3)
        g_aggi_0agg2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_aggi_0agg2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_aggm_0agg2_mul = paddle.multiply(x=g_aggm_0agg2_w0, y=g_aggm_0agg2_Conv2D)
        batch_norm_transpose_4 = paddle.transpose(x=g_aggm_0agg2_Conv2D, perm=[0, 3, 1, 2])
        g_aggm_0agg2_BatchNorm_FusedBatchNorm = self.bn4(batch_norm_transpose_4)
        g_aggm_0agg2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_aggm_0agg2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_aggi_0agg2_mul_1 = paddle.multiply(x=g_aggi_0agg2_w1, y=g_aggi_0agg2_BatchNorm_FusedBatchNorm)
        g_aggm_0agg2_mul_1 = paddle.multiply(x=g_aggm_0agg2_w1, y=g_aggm_0agg2_BatchNorm_FusedBatchNorm)
        g_aggi_0agg2_add = paddle.add(x=g_aggi_0agg2_mul, y=g_aggi_0agg2_mul_1)
        g_aggm_0agg2_add = paddle.add(x=g_aggm_0agg2_mul, y=g_aggm_0agg2_mul_1)
        g_aggi_0agg2_mul_2 = paddle.multiply(x=g_aggi_0agg2_add, y=g_aggi_0agg2_mul_2_y)
        g_aggm_0agg2_mul_2 = paddle.multiply(x=g_aggm_0agg2_add, y=g_aggm_0agg2_mul_2_y)
        g_aggi_0agg2_Maximum = paddle.maximum(x=g_aggi_0agg2_mul_2, y=g_aggi_0agg2_add)
        g_aggm_0agg2_Maximum = paddle.maximum(x=g_aggm_0agg2_mul_2, y=g_aggm_0agg2_add)
        Sigmoid = self.sigmoid2(g_aggm_0agg2_Maximum)
        mul_1 = paddle.multiply(x=g_aggi_0agg2_Maximum, y=Sigmoid)
        mul_1_transpose = paddle.transpose(x=mul_1, perm=[0, 3, 1, 2])
        space_to_batch_pad_0 = paddle.nn.functional.pad(x=mul_1_transpose, pad=[0, 0, 0, 0, 2, 2, 2, 2])
        space_to_batch_pad_0_transpose = paddle.transpose(x=space_to_batch_pad_0, perm=[0, 2, 3, 1])
        space_to_batch_reshape_0 = paddle.reshape(x=space_to_batch_pad_0_transpose, shape=[1, 202, 2, 152, 2, 64])
        space_to_batch_transpose_0 = paddle.transpose(x=space_to_batch_reshape_0, perm=[2, 4, 0, 1, 3, 5])
        g_conv2_SpaceToBatchND = paddle.reshape(x=space_to_batch_transpose_0, shape=[-1, 202, 152, 64])
        conv2d_transpose_19 = paddle.transpose(x=g_conv2_SpaceToBatchND, perm=[0, 3, 1, 2])
        g_conv2_Conv2D = self.conv19(conv2d_transpose_19)
        g_conv2_Conv2D = paddle.transpose(x=g_conv2_Conv2D, perm=[0, 2, 3, 1])
        batch_to_space_reshape_0 = paddle.reshape(x=g_conv2_Conv2D, shape=[2, 2, -1, 200, 150, 64])
        batch_to_space_transpose_0 = paddle.transpose(x=batch_to_space_reshape_0, perm=[2, 3, 0, 4, 1, 5])
        batch_to_space_reshape_1 = paddle.reshape(x=batch_to_space_transpose_0, shape=[-1, 400, 300, 64])
        g_conv2_BatchToSpaceND = paddle.crop(x=batch_to_space_reshape_1, shape=[-1, 400, 300, 64], offsets=[0, 0, 0, 0])
        g_conv2_mul = paddle.multiply(x=g_conv2_w0, y=g_conv2_BatchToSpaceND)
        batch_norm_transpose_5 = paddle.transpose(x=g_conv2_BatchToSpaceND, perm=[0, 3, 1, 2])
        g_conv2_BatchNorm_FusedBatchNorm = self.bn5(batch_norm_transpose_5)
        g_conv2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_conv2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_conv2_mul_1 = paddle.multiply(x=g_conv2_w1, y=g_conv2_BatchNorm_FusedBatchNorm)
        g_conv2_add = paddle.add(x=g_conv2_mul, y=g_conv2_mul_1)
        g_conv2_mul_2 = paddle.multiply(x=g_conv2_add, y=g_conv2_mul_2_y)
        g_conv2_Maximum = paddle.maximum(x=g_conv2_mul_2, y=g_conv2_add)
        g_conv2_Maximum_transpose = paddle.transpose(x=g_conv2_Maximum, perm=[0, 3, 1, 2])
        space_to_batch_pad_1 = paddle.nn.functional.pad(x=g_conv2_Maximum_transpose, pad=[0, 0, 0, 0, 4, 4, 4, 4])
        space_to_batch_pad_1_transpose = paddle.transpose(x=space_to_batch_pad_1, perm=[0, 2, 3, 1])
        space_to_batch_reshape_1 = paddle.reshape(x=space_to_batch_pad_1_transpose, shape=[1, 102, 4, 77, 4, 64])
        space_to_batch_transpose_1 = paddle.transpose(x=space_to_batch_reshape_1, perm=[2, 4, 0, 1, 3, 5])
        g_conv3_SpaceToBatchND = paddle.reshape(x=space_to_batch_transpose_1, shape=[-1, 102, 77, 64])
        conv2d_transpose_20 = paddle.transpose(x=g_conv3_SpaceToBatchND, perm=[0, 3, 1, 2])
        g_conv3_Conv2D = self.conv20(conv2d_transpose_20)
        g_conv3_Conv2D = paddle.transpose(x=g_conv3_Conv2D, perm=[0, 2, 3, 1])
        batch_to_space_reshape_2 = paddle.reshape(x=g_conv3_Conv2D, shape=[4, 4, -1, 100, 75, 64])
        batch_to_space_transpose_1 = paddle.transpose(x=batch_to_space_reshape_2, perm=[2, 3, 0, 4, 1, 5])
        batch_to_space_reshape_3 = paddle.reshape(x=batch_to_space_transpose_1, shape=[-1, 400, 300, 64])
        g_conv3_BatchToSpaceND = paddle.crop(x=batch_to_space_reshape_3, shape=[-1, 400, 300, 64], offsets=[0, 0, 0, 0])
        g_conv3_mul = paddle.multiply(x=g_conv3_w0, y=g_conv3_BatchToSpaceND)
        batch_norm_transpose_6 = paddle.transpose(x=g_conv3_BatchToSpaceND, perm=[0, 3, 1, 2])
        g_conv3_BatchNorm_FusedBatchNorm = self.bn6(batch_norm_transpose_6)
        g_conv3_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_conv3_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_conv3_mul_1 = paddle.multiply(x=g_conv3_w1, y=g_conv3_BatchNorm_FusedBatchNorm)
        g_conv3_add = paddle.add(x=g_conv3_mul, y=g_conv3_mul_1)
        g_conv3_mul_2 = paddle.multiply(x=g_conv3_add, y=g_conv3_mul_2_y)
        g_conv3_Maximum = paddle.maximum(x=g_conv3_mul_2, y=g_conv3_add)
        concat_6 = paddle.concat(x=[g_aggi_0agg2_Maximum, g_conv3_Maximum, g_conv2_Maximum], axis=3)
        concat_7 = paddle.concat(x=[g_aggm_0agg2_Maximum, g_conv3_Maximum, g_conv2_Maximum], axis=3)
        g_aggi_1att2_Mean = paddle.mean(x=concat_6, axis=[1, 2], keepdim=True)
        g_aggm_1att2_Mean = paddle.mean(x=concat_7, axis=[1, 2], keepdim=True)
        g_aggi_1att2_bottleneck_fc_Tensordot_transpose = paddle.transpose(x=g_aggi_1att2_Mean, perm=[0, 1, 2, 3])
        g_aggm_1att2_bottleneck_fc_Tensordot_transpose = paddle.transpose(x=g_aggm_1att2_Mean, perm=[0, 1, 2, 3])
        g_aggi_1att2_bottleneck_fc_Tensordot_Reshape = paddle.reshape(x=g_aggi_1att2_bottleneck_fc_Tensordot_transpose, shape=[1, 192])
        g_aggm_1att2_bottleneck_fc_Tensordot_Reshape = paddle.reshape(x=g_aggm_1att2_bottleneck_fc_Tensordot_transpose, shape=[1, 192])
        g_aggi_1att2_bottleneck_fc_Tensordot_MatMul = paddle.matmul(x=g_aggi_1att2_bottleneck_fc_Tensordot_Reshape, y=g_aggi_1att2_bottleneck_fc_Tensordot_Reshape_1)
        g_aggm_1att2_bottleneck_fc_Tensordot_MatMul = paddle.matmul(x=g_aggm_1att2_bottleneck_fc_Tensordot_Reshape, y=g_aggm_1att2_bottleneck_fc_Tensordot_Reshape_1)
        g_aggi_1att2_bottleneck_fc_Tensordot = paddle.reshape(x=g_aggi_1att2_bottleneck_fc_Tensordot_MatMul, shape=[1, 1, 1, 24])
        g_aggm_1att2_bottleneck_fc_Tensordot = paddle.reshape(x=g_aggm_1att2_bottleneck_fc_Tensordot_MatMul, shape=[1, 1, 1, 24])
        g_aggi_1att2_bottleneck_fc_BiasAdd = paddle.add(x=g_aggi_1att2_bottleneck_fc_Tensordot, y=g_aggi_1att2_bottleneck_fc_bias)
        g_aggm_1att2_bottleneck_fc_BiasAdd = paddle.add(x=g_aggm_1att2_bottleneck_fc_Tensordot, y=g_aggm_1att2_bottleneck_fc_bias)
        g_aggi_1att2_bottleneck_fc_Relu = self.relu16(g_aggi_1att2_bottleneck_fc_BiasAdd)
        g_aggm_1att2_bottleneck_fc_Relu = self.relu17(g_aggm_1att2_bottleneck_fc_BiasAdd)
        g_aggi_1att2_recover_fc_Tensordot_transpose = paddle.transpose(x=g_aggi_1att2_bottleneck_fc_Relu, perm=[0, 1, 2, 3])
        g_aggm_1att2_recover_fc_Tensordot_transpose = paddle.transpose(x=g_aggm_1att2_bottleneck_fc_Relu, perm=[0, 1, 2, 3])
        g_aggi_1att2_recover_fc_Tensordot_Reshape = paddle.reshape(x=g_aggi_1att2_recover_fc_Tensordot_transpose, shape=[1, 24])
        g_aggm_1att2_recover_fc_Tensordot_Reshape = paddle.reshape(x=g_aggm_1att2_recover_fc_Tensordot_transpose, shape=[1, 24])
        g_aggi_1att2_recover_fc_Tensordot_MatMul = paddle.matmul(x=g_aggi_1att2_recover_fc_Tensordot_Reshape, y=g_aggi_1att2_recover_fc_Tensordot_Reshape_1)
        g_aggm_1att2_recover_fc_Tensordot_MatMul = paddle.matmul(x=g_aggm_1att2_recover_fc_Tensordot_Reshape, y=g_aggm_1att2_recover_fc_Tensordot_Reshape_1)
        g_aggi_1att2_recover_fc_Tensordot = paddle.reshape(x=g_aggi_1att2_recover_fc_Tensordot_MatMul, shape=[1, 1, 1, 192])
        g_aggm_1att2_recover_fc_Tensordot = paddle.reshape(x=g_aggm_1att2_recover_fc_Tensordot_MatMul, shape=[1, 1, 1, 192])
        g_aggi_1att2_recover_fc_BiasAdd = paddle.add(x=g_aggi_1att2_recover_fc_Tensordot, y=g_aggi_1att2_recover_fc_bias)
        g_aggm_1att2_recover_fc_BiasAdd = paddle.add(x=g_aggm_1att2_recover_fc_Tensordot, y=g_aggm_1att2_recover_fc_bias)
        g_aggi_1att2_recover_fc_Sigmoid = self.sigmoid3(g_aggi_1att2_recover_fc_BiasAdd)
        g_aggm_1att2_recover_fc_Sigmoid = self.sigmoid4(g_aggm_1att2_recover_fc_BiasAdd)
        g_aggi_1att2_mul = paddle.multiply(x=concat_6, y=g_aggi_1att2_recover_fc_Sigmoid)
        g_aggm_1att2_mul = paddle.multiply(x=concat_7, y=g_aggm_1att2_recover_fc_Sigmoid)
        conv2d_transpose_21 = paddle.transpose(x=g_aggi_1att2_mul, perm=[0, 3, 1, 2])
        g_aggi_1agg2_Conv2D = self.conv21(conv2d_transpose_21)
        g_aggi_1agg2_Conv2D = paddle.transpose(x=g_aggi_1agg2_Conv2D, perm=[0, 2, 3, 1])
        conv2d_transpose_22 = paddle.transpose(x=g_aggm_1att2_mul, perm=[0, 3, 1, 2])
        g_aggm_1agg2_Conv2D = self.conv22(conv2d_transpose_22)
        g_aggm_1agg2_Conv2D = paddle.transpose(x=g_aggm_1agg2_Conv2D, perm=[0, 2, 3, 1])
        g_aggi_1agg2_mul = paddle.multiply(x=g_aggi_1agg2_w0, y=g_aggi_1agg2_Conv2D)
        batch_norm_transpose_7 = paddle.transpose(x=g_aggi_1agg2_Conv2D, perm=[0, 3, 1, 2])
        g_aggi_1agg2_BatchNorm_FusedBatchNorm = self.bn7(batch_norm_transpose_7)
        g_aggi_1agg2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_aggi_1agg2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_aggm_1agg2_mul = paddle.multiply(x=g_aggm_1agg2_w0, y=g_aggm_1agg2_Conv2D)
        batch_norm_transpose_8 = paddle.transpose(x=g_aggm_1agg2_Conv2D, perm=[0, 3, 1, 2])
        g_aggm_1agg2_BatchNorm_FusedBatchNorm = self.bn8(batch_norm_transpose_8)
        g_aggm_1agg2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_aggm_1agg2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_aggi_1agg2_mul_1 = paddle.multiply(x=g_aggi_1agg2_w1, y=g_aggi_1agg2_BatchNorm_FusedBatchNorm)
        g_aggm_1agg2_mul_1 = paddle.multiply(x=g_aggm_1agg2_w1, y=g_aggm_1agg2_BatchNorm_FusedBatchNorm)
        g_aggi_1agg2_add = paddle.add(x=g_aggi_1agg2_mul, y=g_aggi_1agg2_mul_1)
        g_aggm_1agg2_add = paddle.add(x=g_aggm_1agg2_mul, y=g_aggm_1agg2_mul_1)
        g_aggi_1agg2_mul_2 = paddle.multiply(x=g_aggi_1agg2_add, y=g_aggi_1agg2_mul_2_y)
        g_aggm_1agg2_mul_2 = paddle.multiply(x=g_aggm_1agg2_add, y=g_aggm_1agg2_mul_2_y)
        g_aggi_1agg2_Maximum = paddle.maximum(x=g_aggi_1agg2_mul_2, y=g_aggi_1agg2_add)
        g_aggm_1agg2_Maximum = paddle.maximum(x=g_aggm_1agg2_mul_2, y=g_aggm_1agg2_add)
        Sigmoid_1 = self.sigmoid5(g_aggm_1agg2_Maximum)
        mul_2 = paddle.multiply(x=g_aggi_1agg2_Maximum, y=Sigmoid_1)
        mul_2_transpose = paddle.transpose(x=mul_2, perm=[0, 3, 1, 2])
        space_to_batch_pad_2 = paddle.nn.functional.pad(x=mul_2_transpose, pad=[0, 0, 0, 0, 8, 8, 8, 12])
        space_to_batch_pad_2_transpose = paddle.transpose(x=space_to_batch_pad_2, perm=[0, 2, 3, 1])
        space_to_batch_reshape_2 = paddle.reshape(x=space_to_batch_pad_2_transpose, shape=[1, 52, 8, 40, 8, 64])
        space_to_batch_transpose_2 = paddle.transpose(x=space_to_batch_reshape_2, perm=[2, 4, 0, 1, 3, 5])
        g_conv4_SpaceToBatchND = paddle.reshape(x=space_to_batch_transpose_2, shape=[-1, 52, 40, 64])
        conv2d_transpose_23 = paddle.transpose(x=g_conv4_SpaceToBatchND, perm=[0, 3, 1, 2])
        g_conv4_Conv2D = self.conv23(conv2d_transpose_23)
        g_conv4_Conv2D = paddle.transpose(x=g_conv4_Conv2D, perm=[0, 2, 3, 1])
        batch_to_space_reshape_4 = paddle.reshape(x=g_conv4_Conv2D, shape=[8, 8, -1, 50, 38, 64])
        batch_to_space_transpose_2 = paddle.transpose(x=batch_to_space_reshape_4, perm=[2, 3, 0, 4, 1, 5])
        batch_to_space_reshape_5 = paddle.reshape(x=batch_to_space_transpose_2, shape=[-1, 400, 304, 64])
        g_conv4_BatchToSpaceND = paddle.crop(x=batch_to_space_reshape_5, shape=[-1, 400, 300, 64], offsets=[0, 0, 0, 0])
        g_conv4_mul = paddle.multiply(x=g_conv4_w0, y=g_conv4_BatchToSpaceND)
        batch_norm_transpose_9 = paddle.transpose(x=g_conv4_BatchToSpaceND, perm=[0, 3, 1, 2])
        g_conv4_BatchNorm_FusedBatchNorm = self.bn9(batch_norm_transpose_9)
        g_conv4_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_conv4_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_conv4_mul_1 = paddle.multiply(x=g_conv4_w1, y=g_conv4_BatchNorm_FusedBatchNorm)
        g_conv4_add = paddle.add(x=g_conv4_mul, y=g_conv4_mul_1)
        g_conv4_mul_2 = paddle.multiply(x=g_conv4_add, y=g_conv4_mul_2_y)
        g_conv4_Maximum = paddle.maximum(x=g_conv4_mul_2, y=g_conv4_add)
        g_conv4_Maximum_transpose = paddle.transpose(x=g_conv4_Maximum, perm=[0, 3, 1, 2])
        space_to_batch_pad_3 = paddle.nn.functional.pad(x=g_conv4_Maximum_transpose, pad=[0, 0, 0, 0, 16, 16, 16, 20])
        space_to_batch_pad_3_transpose = paddle.transpose(x=space_to_batch_pad_3, perm=[0, 2, 3, 1])
        space_to_batch_reshape_3 = paddle.reshape(x=space_to_batch_pad_3_transpose, shape=[1, 27, 16, 21, 16, 64])
        space_to_batch_transpose_3 = paddle.transpose(x=space_to_batch_reshape_3, perm=[2, 4, 0, 1, 3, 5])
        g_conv5_SpaceToBatchND = paddle.reshape(x=space_to_batch_transpose_3, shape=[-1, 27, 21, 64])
        conv2d_transpose_24 = paddle.transpose(x=g_conv5_SpaceToBatchND, perm=[0, 3, 1, 2])
        g_conv5_Conv2D = self.conv24(conv2d_transpose_24)
        g_conv5_Conv2D = paddle.transpose(x=g_conv5_Conv2D, perm=[0, 2, 3, 1])
        batch_to_space_reshape_6 = paddle.reshape(x=g_conv5_Conv2D, shape=[16, 16, -1, 25, 19, 64])
        batch_to_space_transpose_3 = paddle.transpose(x=batch_to_space_reshape_6, perm=[2, 3, 0, 4, 1, 5])
        batch_to_space_reshape_7 = paddle.reshape(x=batch_to_space_transpose_3, shape=[-1, 400, 304, 64])
        g_conv5_BatchToSpaceND = paddle.crop(x=batch_to_space_reshape_7, shape=[-1, 400, 300, 64], offsets=[0, 0, 0, 0])
        g_conv5_mul = paddle.multiply(x=g_conv5_w0, y=g_conv5_BatchToSpaceND)
        batch_norm_transpose_10 = paddle.transpose(x=g_conv5_BatchToSpaceND, perm=[0, 3, 1, 2])
        g_conv5_BatchNorm_FusedBatchNorm = self.bn10(batch_norm_transpose_10)
        g_conv5_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_conv5_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_conv5_mul_1 = paddle.multiply(x=g_conv5_w1, y=g_conv5_BatchNorm_FusedBatchNorm)
        g_conv5_add = paddle.add(x=g_conv5_mul, y=g_conv5_mul_1)
        g_conv5_mul_2 = paddle.multiply(x=g_conv5_add, y=g_conv5_mul_2_y)
        g_conv5_Maximum = paddle.maximum(x=g_conv5_mul_2, y=g_conv5_add)
        concat_8 = paddle.concat(x=[g_aggi_1agg2_Maximum, g_conv5_Maximum, g_conv4_Maximum], axis=3)
        concat_9 = paddle.concat(x=[g_aggm_1agg2_Maximum, g_conv5_Maximum, g_conv4_Maximum], axis=3)
        g_aggi_2att2_Mean = paddle.mean(x=concat_8, axis=[1, 2], keepdim=True)
        g_aggm_2att2_Mean = paddle.mean(x=concat_9, axis=[1, 2], keepdim=True)
        g_aggi_2att2_bottleneck_fc_Tensordot_transpose = paddle.transpose(x=g_aggi_2att2_Mean, perm=[0, 1, 2, 3])
        g_aggm_2att2_bottleneck_fc_Tensordot_transpose = paddle.transpose(x=g_aggm_2att2_Mean, perm=[0, 1, 2, 3])
        g_aggi_2att2_bottleneck_fc_Tensordot_Reshape = paddle.reshape(x=g_aggi_2att2_bottleneck_fc_Tensordot_transpose, shape=[1, 192])
        g_aggm_2att2_bottleneck_fc_Tensordot_Reshape = paddle.reshape(x=g_aggm_2att2_bottleneck_fc_Tensordot_transpose, shape=[1, 192])
        g_aggi_2att2_bottleneck_fc_Tensordot_MatMul = paddle.matmul(x=g_aggi_2att2_bottleneck_fc_Tensordot_Reshape, y=g_aggi_2att2_bottleneck_fc_Tensordot_Reshape_1)
        g_aggm_2att2_bottleneck_fc_Tensordot_MatMul = paddle.matmul(x=g_aggm_2att2_bottleneck_fc_Tensordot_Reshape, y=g_aggm_2att2_bottleneck_fc_Tensordot_Reshape_1)
        g_aggi_2att2_bottleneck_fc_Tensordot = paddle.reshape(x=g_aggi_2att2_bottleneck_fc_Tensordot_MatMul, shape=[1, 1, 1, 24])
        g_aggm_2att2_bottleneck_fc_Tensordot = paddle.reshape(x=g_aggm_2att2_bottleneck_fc_Tensordot_MatMul, shape=[1, 1, 1, 24])
        g_aggi_2att2_bottleneck_fc_BiasAdd = paddle.add(x=g_aggi_2att2_bottleneck_fc_Tensordot, y=g_aggi_2att2_bottleneck_fc_bias)
        g_aggm_2att2_bottleneck_fc_BiasAdd = paddle.add(x=g_aggm_2att2_bottleneck_fc_Tensordot, y=g_aggm_2att2_bottleneck_fc_bias)
        g_aggi_2att2_bottleneck_fc_Relu = self.relu18(g_aggi_2att2_bottleneck_fc_BiasAdd)
        g_aggm_2att2_bottleneck_fc_Relu = self.relu19(g_aggm_2att2_bottleneck_fc_BiasAdd)
        g_aggi_2att2_recover_fc_Tensordot_transpose = paddle.transpose(x=g_aggi_2att2_bottleneck_fc_Relu, perm=[0, 1, 2, 3])
        g_aggm_2att2_recover_fc_Tensordot_transpose = paddle.transpose(x=g_aggm_2att2_bottleneck_fc_Relu, perm=[0, 1, 2, 3])
        g_aggi_2att2_recover_fc_Tensordot_Reshape = paddle.reshape(x=g_aggi_2att2_recover_fc_Tensordot_transpose, shape=[1, 24])
        g_aggm_2att2_recover_fc_Tensordot_Reshape = paddle.reshape(x=g_aggm_2att2_recover_fc_Tensordot_transpose, shape=[1, 24])
        g_aggi_2att2_recover_fc_Tensordot_MatMul = paddle.matmul(x=g_aggi_2att2_recover_fc_Tensordot_Reshape, y=g_aggi_2att2_recover_fc_Tensordot_Reshape_1)
        g_aggm_2att2_recover_fc_Tensordot_MatMul = paddle.matmul(x=g_aggm_2att2_recover_fc_Tensordot_Reshape, y=g_aggm_2att2_recover_fc_Tensordot_Reshape_1)
        g_aggi_2att2_recover_fc_Tensordot = paddle.reshape(x=g_aggi_2att2_recover_fc_Tensordot_MatMul, shape=[1, 1, 1, 192])
        g_aggm_2att2_recover_fc_Tensordot = paddle.reshape(x=g_aggm_2att2_recover_fc_Tensordot_MatMul, shape=[1, 1, 1, 192])
        g_aggi_2att2_recover_fc_BiasAdd = paddle.add(x=g_aggi_2att2_recover_fc_Tensordot, y=g_aggi_2att2_recover_fc_bias)
        g_aggm_2att2_recover_fc_BiasAdd = paddle.add(x=g_aggm_2att2_recover_fc_Tensordot, y=g_aggm_2att2_recover_fc_bias)
        g_aggi_2att2_recover_fc_Sigmoid = self.sigmoid6(g_aggi_2att2_recover_fc_BiasAdd)
        g_aggm_2att2_recover_fc_Sigmoid = self.sigmoid7(g_aggm_2att2_recover_fc_BiasAdd)
        g_aggi_2att2_mul = paddle.multiply(x=concat_8, y=g_aggi_2att2_recover_fc_Sigmoid)
        g_aggm_2att2_mul = paddle.multiply(x=concat_9, y=g_aggm_2att2_recover_fc_Sigmoid)
        conv2d_transpose_25 = paddle.transpose(x=g_aggi_2att2_mul, perm=[0, 3, 1, 2])
        g_aggi_2agg2_Conv2D = self.conv25(conv2d_transpose_25)
        g_aggi_2agg2_Conv2D = paddle.transpose(x=g_aggi_2agg2_Conv2D, perm=[0, 2, 3, 1])
        conv2d_transpose_26 = paddle.transpose(x=g_aggm_2att2_mul, perm=[0, 3, 1, 2])
        g_aggm_2agg2_Conv2D = self.conv26(conv2d_transpose_26)
        g_aggm_2agg2_Conv2D = paddle.transpose(x=g_aggm_2agg2_Conv2D, perm=[0, 2, 3, 1])
        g_aggi_2agg2_mul = paddle.multiply(x=g_aggi_2agg2_w0, y=g_aggi_2agg2_Conv2D)
        batch_norm_transpose_11 = paddle.transpose(x=g_aggi_2agg2_Conv2D, perm=[0, 3, 1, 2])
        g_aggi_2agg2_BatchNorm_FusedBatchNorm = self.bn11(batch_norm_transpose_11)
        g_aggi_2agg2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_aggi_2agg2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_aggm_2agg2_mul = paddle.multiply(x=g_aggm_2agg2_w0, y=g_aggm_2agg2_Conv2D)
        batch_norm_transpose_12 = paddle.transpose(x=g_aggm_2agg2_Conv2D, perm=[0, 3, 1, 2])
        g_aggm_2agg2_BatchNorm_FusedBatchNorm = self.bn12(batch_norm_transpose_12)
        g_aggm_2agg2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_aggm_2agg2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_aggi_2agg2_mul_1 = paddle.multiply(x=g_aggi_2agg2_w1, y=g_aggi_2agg2_BatchNorm_FusedBatchNorm)
        g_aggm_2agg2_mul_1 = paddle.multiply(x=g_aggm_2agg2_w1, y=g_aggm_2agg2_BatchNorm_FusedBatchNorm)
        g_aggi_2agg2_add = paddle.add(x=g_aggi_2agg2_mul, y=g_aggi_2agg2_mul_1)
        g_aggm_2agg2_add = paddle.add(x=g_aggm_2agg2_mul, y=g_aggm_2agg2_mul_1)
        g_aggi_2agg2_mul_2 = paddle.multiply(x=g_aggi_2agg2_add, y=g_aggi_2agg2_mul_2_y)
        g_aggm_2agg2_mul_2 = paddle.multiply(x=g_aggm_2agg2_add, y=g_aggm_2agg2_mul_2_y)
        g_aggi_2agg2_Maximum = paddle.maximum(x=g_aggi_2agg2_mul_2, y=g_aggi_2agg2_add)
        g_aggm_2agg2_Maximum = paddle.maximum(x=g_aggm_2agg2_mul_2, y=g_aggm_2agg2_add)
        Sigmoid_2 = self.sigmoid8(g_aggm_2agg2_Maximum)
        mul_3 = paddle.multiply(x=g_aggi_2agg2_Maximum, y=Sigmoid_2)
        mul_3_transpose = paddle.transpose(x=mul_3, perm=[0, 3, 1, 2])
        space_to_batch_pad_4 = paddle.nn.functional.pad(x=mul_3_transpose, pad=[0, 0, 0, 0, 32, 48, 32, 52])
        space_to_batch_pad_4_transpose = paddle.transpose(x=space_to_batch_pad_4, perm=[0, 2, 3, 1])
        space_to_batch_reshape_4 = paddle.reshape(x=space_to_batch_pad_4_transpose, shape=[1, 15, 32, 12, 32, 64])
        space_to_batch_transpose_4 = paddle.transpose(x=space_to_batch_reshape_4, perm=[2, 4, 0, 1, 3, 5])
        g_conv6_SpaceToBatchND = paddle.reshape(x=space_to_batch_transpose_4, shape=[-1, 15, 12, 64])
        conv2d_transpose_27 = paddle.transpose(x=g_conv6_SpaceToBatchND, perm=[0, 3, 1, 2])
        g_conv6_Conv2D = self.conv27(conv2d_transpose_27)
        g_conv6_Conv2D = paddle.transpose(x=g_conv6_Conv2D, perm=[0, 2, 3, 1])
        batch_to_space_reshape_8 = paddle.reshape(x=g_conv6_Conv2D, shape=[32, 32, -1, 13, 10, 64])
        batch_to_space_transpose_4 = paddle.transpose(x=batch_to_space_reshape_8, perm=[2, 3, 0, 4, 1, 5])
        batch_to_space_reshape_9 = paddle.reshape(x=batch_to_space_transpose_4, shape=[-1, 416, 320, 64])
        g_conv6_BatchToSpaceND = paddle.crop(x=batch_to_space_reshape_9, shape=[-1, 400, 300, 64], offsets=[0, 0, 0, 0])
        g_conv6_mul = paddle.multiply(x=g_conv6_w0, y=g_conv6_BatchToSpaceND)
        batch_norm_transpose_13 = paddle.transpose(x=g_conv6_BatchToSpaceND, perm=[0, 3, 1, 2])
        g_conv6_BatchNorm_FusedBatchNorm = self.bn13(batch_norm_transpose_13)
        g_conv6_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_conv6_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_conv6_mul_1 = paddle.multiply(x=g_conv6_w1, y=g_conv6_BatchNorm_FusedBatchNorm)
        g_conv6_add = paddle.add(x=g_conv6_mul, y=g_conv6_mul_1)
        g_conv6_mul_2 = paddle.multiply(x=g_conv6_add, y=g_conv6_mul_2_y)
        g_conv6_Maximum = paddle.maximum(x=g_conv6_mul_2, y=g_conv6_add)
        g_conv6_Maximum_transpose = paddle.transpose(x=g_conv6_Maximum, perm=[0, 3, 1, 2])
        space_to_batch_pad_5 = paddle.nn.functional.pad(x=g_conv6_Maximum_transpose, pad=[0, 0, 0, 0, 64, 112, 64, 84])
        space_to_batch_pad_5_transpose = paddle.transpose(x=space_to_batch_pad_5, perm=[0, 2, 3, 1])
        space_to_batch_reshape_5 = paddle.reshape(x=space_to_batch_pad_5_transpose, shape=[1, 9, 64, 7, 64, 64])
        space_to_batch_transpose_5 = paddle.transpose(x=space_to_batch_reshape_5, perm=[2, 4, 0, 1, 3, 5])
        g_conv7_SpaceToBatchND = paddle.reshape(x=space_to_batch_transpose_5, shape=[-1, 9, 7, 64])
        conv2d_transpose_28 = paddle.transpose(x=g_conv7_SpaceToBatchND, perm=[0, 3, 1, 2])
        g_conv7_Conv2D = self.conv28(conv2d_transpose_28)
        g_conv7_Conv2D = paddle.transpose(x=g_conv7_Conv2D, perm=[0, 2, 3, 1])
        batch_to_space_reshape_10 = paddle.reshape(x=g_conv7_Conv2D, shape=[64, 64, -1, 7, 5, 64])
        batch_to_space_transpose_5 = paddle.transpose(x=batch_to_space_reshape_10, perm=[2, 3, 0, 4, 1, 5])
        batch_to_space_reshape_11 = paddle.reshape(x=batch_to_space_transpose_5, shape=[-1, 448, 320, 64])
        g_conv7_BatchToSpaceND = paddle.crop(x=batch_to_space_reshape_11, shape=[-1, 400, 300, 64], offsets=[0, 0, 0, 0])
        g_conv7_mul = paddle.multiply(x=g_conv7_w0, y=g_conv7_BatchToSpaceND)
        batch_norm_transpose_14 = paddle.transpose(x=g_conv7_BatchToSpaceND, perm=[0, 3, 1, 2])
        g_conv7_BatchNorm_FusedBatchNorm = self.bn14(batch_norm_transpose_14)
        g_conv7_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_conv7_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_conv7_mul_1 = paddle.multiply(x=g_conv7_w1, y=g_conv7_BatchNorm_FusedBatchNorm)
        g_conv7_add = paddle.add(x=g_conv7_mul, y=g_conv7_mul_1)
        g_conv7_mul_2 = paddle.multiply(x=g_conv7_add, y=g_conv7_mul_2_y)
        g_conv7_Maximum = paddle.maximum(x=g_conv7_mul_2, y=g_conv7_add)
        concat_10 = paddle.concat(x=[g_aggi_1agg2_Maximum, g_aggi_2agg2_Maximum, g_conv6_Maximum, g_conv7_Maximum], axis=3)
        concat_11 = paddle.concat(x=[g_aggm_1agg2_Maximum, g_aggm_2agg2_Maximum, g_conv6_Maximum, g_conv7_Maximum], axis=3)
        g_aggi_3att2_Mean = paddle.mean(x=concat_10, axis=[1, 2], keepdim=True)
        g_aggm_3att2_Mean = paddle.mean(x=concat_11, axis=[1, 2], keepdim=True)
        g_aggi_3att2_bottleneck_fc_Tensordot_transpose = paddle.transpose(x=g_aggi_3att2_Mean, perm=[0, 1, 2, 3])
        g_aggm_3att2_bottleneck_fc_Tensordot_transpose = paddle.transpose(x=g_aggm_3att2_Mean, perm=[0, 1, 2, 3])
        g_aggi_3att2_bottleneck_fc_Tensordot_Reshape = paddle.reshape(x=g_aggi_3att2_bottleneck_fc_Tensordot_transpose, shape=[1, 256])
        g_aggm_3att2_bottleneck_fc_Tensordot_Reshape = paddle.reshape(x=g_aggm_3att2_bottleneck_fc_Tensordot_transpose, shape=[1, 256])
        g_aggi_3att2_bottleneck_fc_Tensordot_MatMul = paddle.matmul(x=g_aggi_3att2_bottleneck_fc_Tensordot_Reshape, y=g_aggi_3att2_bottleneck_fc_Tensordot_Reshape_1)
        g_aggm_3att2_bottleneck_fc_Tensordot_MatMul = paddle.matmul(x=g_aggm_3att2_bottleneck_fc_Tensordot_Reshape, y=g_aggm_3att2_bottleneck_fc_Tensordot_Reshape_1)
        g_aggi_3att2_bottleneck_fc_Tensordot = paddle.reshape(x=g_aggi_3att2_bottleneck_fc_Tensordot_MatMul, shape=[1, 1, 1, 32])
        g_aggm_3att2_bottleneck_fc_Tensordot = paddle.reshape(x=g_aggm_3att2_bottleneck_fc_Tensordot_MatMul, shape=[1, 1, 1, 32])
        g_aggi_3att2_bottleneck_fc_BiasAdd = paddle.add(x=g_aggi_3att2_bottleneck_fc_Tensordot, y=g_aggi_3att2_bottleneck_fc_bias)
        g_aggm_3att2_bottleneck_fc_BiasAdd = paddle.add(x=g_aggm_3att2_bottleneck_fc_Tensordot, y=g_aggm_3att2_bottleneck_fc_bias)
        g_aggi_3att2_bottleneck_fc_Relu = self.relu20(g_aggi_3att2_bottleneck_fc_BiasAdd)
        g_aggm_3att2_bottleneck_fc_Relu = self.relu21(g_aggm_3att2_bottleneck_fc_BiasAdd)
        g_aggi_3att2_recover_fc_Tensordot_transpose = paddle.transpose(x=g_aggi_3att2_bottleneck_fc_Relu, perm=[0, 1, 2, 3])
        g_aggm_3att2_recover_fc_Tensordot_transpose = paddle.transpose(x=g_aggm_3att2_bottleneck_fc_Relu, perm=[0, 1, 2, 3])
        g_aggi_3att2_recover_fc_Tensordot_Reshape = paddle.reshape(x=g_aggi_3att2_recover_fc_Tensordot_transpose, shape=[1, 32])
        g_aggm_3att2_recover_fc_Tensordot_Reshape = paddle.reshape(x=g_aggm_3att2_recover_fc_Tensordot_transpose, shape=[1, 32])
        g_aggi_3att2_recover_fc_Tensordot_MatMul = paddle.matmul(x=g_aggi_3att2_recover_fc_Tensordot_Reshape, y=g_aggi_3att2_recover_fc_Tensordot_Reshape_1)
        g_aggm_3att2_recover_fc_Tensordot_MatMul = paddle.matmul(x=g_aggm_3att2_recover_fc_Tensordot_Reshape, y=g_aggm_3att2_recover_fc_Tensordot_Reshape_1)
        g_aggi_3att2_recover_fc_Tensordot = paddle.reshape(x=g_aggi_3att2_recover_fc_Tensordot_MatMul, shape=[1, 1, 1, 256])
        g_aggm_3att2_recover_fc_Tensordot = paddle.reshape(x=g_aggm_3att2_recover_fc_Tensordot_MatMul, shape=[1, 1, 1, 256])
        g_aggi_3att2_recover_fc_BiasAdd = paddle.add(x=g_aggi_3att2_recover_fc_Tensordot, y=g_aggi_3att2_recover_fc_bias)
        g_aggm_3att2_recover_fc_BiasAdd = paddle.add(x=g_aggm_3att2_recover_fc_Tensordot, y=g_aggm_3att2_recover_fc_bias)
        g_aggi_3att2_recover_fc_Sigmoid = self.sigmoid9(g_aggi_3att2_recover_fc_BiasAdd)
        g_aggm_3att2_recover_fc_Sigmoid = self.sigmoid10(g_aggm_3att2_recover_fc_BiasAdd)
        g_aggi_3att2_mul = paddle.multiply(x=concat_10, y=g_aggi_3att2_recover_fc_Sigmoid)
        g_aggm_3att2_mul = paddle.multiply(x=concat_11, y=g_aggm_3att2_recover_fc_Sigmoid)
        conv2d_transpose_29 = paddle.transpose(x=g_aggi_3att2_mul, perm=[0, 3, 1, 2])
        g_aggi_3agg2_Conv2D = self.conv29(conv2d_transpose_29)
        g_aggi_3agg2_Conv2D = paddle.transpose(x=g_aggi_3agg2_Conv2D, perm=[0, 2, 3, 1])
        conv2d_transpose_30 = paddle.transpose(x=g_aggm_3att2_mul, perm=[0, 3, 1, 2])
        g_aggm_3agg2_Conv2D = self.conv30(conv2d_transpose_30)
        g_aggm_3agg2_Conv2D = paddle.transpose(x=g_aggm_3agg2_Conv2D, perm=[0, 2, 3, 1])
        g_aggi_3agg2_mul = paddle.multiply(x=g_aggi_3agg2_w0, y=g_aggi_3agg2_Conv2D)
        batch_norm_transpose_15 = paddle.transpose(x=g_aggi_3agg2_Conv2D, perm=[0, 3, 1, 2])
        g_aggi_3agg2_BatchNorm_FusedBatchNorm = self.bn15(batch_norm_transpose_15)
        g_aggi_3agg2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_aggi_3agg2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_aggm_3agg2_mul = paddle.multiply(x=g_aggm_3agg2_w0, y=g_aggm_3agg2_Conv2D)
        batch_norm_transpose_16 = paddle.transpose(x=g_aggm_3agg2_Conv2D, perm=[0, 3, 1, 2])
        g_aggm_3agg2_BatchNorm_FusedBatchNorm = self.bn16(batch_norm_transpose_16)
        g_aggm_3agg2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_aggm_3agg2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_aggi_3agg2_mul_1 = paddle.multiply(x=g_aggi_3agg2_w1, y=g_aggi_3agg2_BatchNorm_FusedBatchNorm)
        g_aggm_3agg2_mul_1 = paddle.multiply(x=g_aggm_3agg2_w1, y=g_aggm_3agg2_BatchNorm_FusedBatchNorm)
        g_aggi_3agg2_add = paddle.add(x=g_aggi_3agg2_mul, y=g_aggi_3agg2_mul_1)
        g_aggm_3agg2_add = paddle.add(x=g_aggm_3agg2_mul, y=g_aggm_3agg2_mul_1)
        g_aggi_3agg2_mul_2 = paddle.multiply(x=g_aggi_3agg2_add, y=g_aggi_3agg2_mul_2_y)
        g_aggm_3agg2_mul_2 = paddle.multiply(x=g_aggm_3agg2_add, y=g_aggm_3agg2_mul_2_y)
        g_aggi_3agg2_Maximum = paddle.maximum(x=g_aggi_3agg2_mul_2, y=g_aggi_3agg2_add)
        g_aggm_3agg2_Maximum = paddle.maximum(x=g_aggm_3agg2_mul_2, y=g_aggm_3agg2_add)
        avg_pool_transpose_4 = paddle.transpose(x=g_aggi_3agg2_Maximum, perm=[0, 3, 1, 2])
        average_pooling2d_AvgPool = self.pool4(avg_pool_transpose_4)
        avg_pool_transpose_5 = paddle.transpose(x=g_aggi_3agg2_Maximum, perm=[0, 3, 1, 2])
        average_pooling2d_1_AvgPool = self.pool5(avg_pool_transpose_5)
        avg_pool_transpose_6 = paddle.transpose(x=g_aggi_3agg2_Maximum, perm=[0, 3, 1, 2])
        average_pooling2d_2_AvgPool = self.pool6(avg_pool_transpose_6)
        avg_pool_transpose_7 = paddle.transpose(x=g_aggi_3agg2_Maximum, perm=[0, 3, 1, 2])
        average_pooling2d_3_AvgPool = self.pool7(avg_pool_transpose_7)
        avg_pool_transpose_8 = paddle.transpose(x=g_aggm_3agg2_Maximum, perm=[0, 3, 1, 2])
        average_pooling2d_4_AvgPool = self.pool8(avg_pool_transpose_8)
        avg_pool_transpose_9 = paddle.transpose(x=g_aggm_3agg2_Maximum, perm=[0, 3, 1, 2])
        average_pooling2d_5_AvgPool = self.pool9(avg_pool_transpose_9)
        avg_pool_transpose_10 = paddle.transpose(x=g_aggm_3agg2_Maximum, perm=[0, 3, 1, 2])
        average_pooling2d_6_AvgPool = self.pool10(avg_pool_transpose_10)
        avg_pool_transpose_11 = paddle.transpose(x=g_aggm_3agg2_Maximum, perm=[0, 3, 1, 2])
        average_pooling2d_7_AvgPool = self.pool11(avg_pool_transpose_11)
        g_imgpool2_Conv2D = self.conv31(average_pooling2d_AvgPool)
        g_imgpool2_Conv2D = paddle.transpose(x=g_imgpool2_Conv2D, perm=[0, 2, 3, 1])
        g_imgpool8_Conv2D = self.conv32(average_pooling2d_1_AvgPool)
        g_imgpool8_Conv2D = paddle.transpose(x=g_imgpool8_Conv2D, perm=[0, 2, 3, 1])
        g_imgpool16_Conv2D = self.conv33(average_pooling2d_2_AvgPool)
        g_imgpool16_Conv2D = paddle.transpose(x=g_imgpool16_Conv2D, perm=[0, 2, 3, 1])
        g_imgpool32_Conv2D = self.conv34(average_pooling2d_3_AvgPool)
        g_imgpool32_Conv2D = paddle.transpose(x=g_imgpool32_Conv2D, perm=[0, 2, 3, 1])
        g_maskpool2_Conv2D = self.conv35(average_pooling2d_4_AvgPool)
        g_maskpool2_Conv2D = paddle.transpose(x=g_maskpool2_Conv2D, perm=[0, 2, 3, 1])
        g_maskpool8_Conv2D = self.conv36(average_pooling2d_5_AvgPool)
        g_maskpool8_Conv2D = paddle.transpose(x=g_maskpool8_Conv2D, perm=[0, 2, 3, 1])
        g_maskpool16_Conv2D = self.conv37(average_pooling2d_6_AvgPool)
        g_maskpool16_Conv2D = paddle.transpose(x=g_maskpool16_Conv2D, perm=[0, 2, 3, 1])
        g_maskpool32_Conv2D = self.conv38(average_pooling2d_7_AvgPool)
        g_maskpool32_Conv2D = paddle.transpose(x=g_maskpool32_Conv2D, perm=[0, 2, 3, 1])
        g_imgpool2_mul = paddle.multiply(x=g_imgpool2_w0, y=g_imgpool2_Conv2D)
        batch_norm_transpose_17 = paddle.transpose(x=g_imgpool2_Conv2D, perm=[0, 3, 1, 2])
        g_imgpool2_BatchNorm_FusedBatchNorm = self.bn17(batch_norm_transpose_17)
        g_imgpool2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_imgpool2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_imgpool8_mul = paddle.multiply(x=g_imgpool8_w0, y=g_imgpool8_Conv2D)
        batch_norm_transpose_18 = paddle.transpose(x=g_imgpool8_Conv2D, perm=[0, 3, 1, 2])
        g_imgpool8_BatchNorm_FusedBatchNorm = self.bn18(batch_norm_transpose_18)
        g_imgpool8_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_imgpool8_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_imgpool16_mul = paddle.multiply(x=g_imgpool16_w0, y=g_imgpool16_Conv2D)
        batch_norm_transpose_19 = paddle.transpose(x=g_imgpool16_Conv2D, perm=[0, 3, 1, 2])
        g_imgpool16_BatchNorm_FusedBatchNorm = self.bn19(batch_norm_transpose_19)
        g_imgpool16_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_imgpool16_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_imgpool32_mul = paddle.multiply(x=g_imgpool32_w0, y=g_imgpool32_Conv2D)
        batch_norm_transpose_20 = paddle.transpose(x=g_imgpool32_Conv2D, perm=[0, 3, 1, 2])
        g_imgpool32_BatchNorm_FusedBatchNorm = self.bn20(batch_norm_transpose_20)
        g_imgpool32_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_imgpool32_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_maskpool2_mul = paddle.multiply(x=g_maskpool2_w0, y=g_maskpool2_Conv2D)
        batch_norm_transpose_21 = paddle.transpose(x=g_maskpool2_Conv2D, perm=[0, 3, 1, 2])
        g_maskpool2_BatchNorm_FusedBatchNorm = self.bn21(batch_norm_transpose_21)
        g_maskpool2_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_maskpool2_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_maskpool8_mul = paddle.multiply(x=g_maskpool8_w0, y=g_maskpool8_Conv2D)
        batch_norm_transpose_22 = paddle.transpose(x=g_maskpool8_Conv2D, perm=[0, 3, 1, 2])
        g_maskpool8_BatchNorm_FusedBatchNorm = self.bn22(batch_norm_transpose_22)
        g_maskpool8_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_maskpool8_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_maskpool16_mul = paddle.multiply(x=g_maskpool16_w0, y=g_maskpool16_Conv2D)
        batch_norm_transpose_23 = paddle.transpose(x=g_maskpool16_Conv2D, perm=[0, 3, 1, 2])
        g_maskpool16_BatchNorm_FusedBatchNorm = self.bn23(batch_norm_transpose_23)
        g_maskpool16_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_maskpool16_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_maskpool32_mul = paddle.multiply(x=g_maskpool32_w0, y=g_maskpool32_Conv2D)
        batch_norm_transpose_24 = paddle.transpose(x=g_maskpool32_Conv2D, perm=[0, 3, 1, 2])
        g_maskpool32_BatchNorm_FusedBatchNorm = self.bn24(batch_norm_transpose_24)
        g_maskpool32_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_maskpool32_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_imgpool2_mul_1 = paddle.multiply(x=g_imgpool2_w1, y=g_imgpool2_BatchNorm_FusedBatchNorm)
        g_imgpool8_mul_1 = paddle.multiply(x=g_imgpool8_w1, y=g_imgpool8_BatchNorm_FusedBatchNorm)
        g_imgpool16_mul_1 = paddle.multiply(x=g_imgpool16_w1, y=g_imgpool16_BatchNorm_FusedBatchNorm)
        g_imgpool32_mul_1 = paddle.multiply(x=g_imgpool32_w1, y=g_imgpool32_BatchNorm_FusedBatchNorm)
        g_maskpool2_mul_1 = paddle.multiply(x=g_maskpool2_w1, y=g_maskpool2_BatchNorm_FusedBatchNorm)
        g_maskpool8_mul_1 = paddle.multiply(x=g_maskpool8_w1, y=g_maskpool8_BatchNorm_FusedBatchNorm)
        g_maskpool16_mul_1 = paddle.multiply(x=g_maskpool16_w1, y=g_maskpool16_BatchNorm_FusedBatchNorm)
        g_maskpool32_mul_1 = paddle.multiply(x=g_maskpool32_w1, y=g_maskpool32_BatchNorm_FusedBatchNorm)
        g_imgpool2_add = paddle.add(x=g_imgpool2_mul, y=g_imgpool2_mul_1)
        g_imgpool8_add = paddle.add(x=g_imgpool8_mul, y=g_imgpool8_mul_1)
        g_imgpool16_add = paddle.add(x=g_imgpool16_mul, y=g_imgpool16_mul_1)
        g_imgpool32_add = paddle.add(x=g_imgpool32_mul, y=g_imgpool32_mul_1)
        g_maskpool2_add = paddle.add(x=g_maskpool2_mul, y=g_maskpool2_mul_1)
        g_maskpool8_add = paddle.add(x=g_maskpool8_mul, y=g_maskpool8_mul_1)
        g_maskpool16_add = paddle.add(x=g_maskpool16_mul, y=g_maskpool16_mul_1)
        g_maskpool32_add = paddle.add(x=g_maskpool32_mul, y=g_maskpool32_mul_1)
        g_imgpool2_mul_2 = paddle.multiply(x=g_imgpool2_add, y=g_imgpool2_mul_2_y)
        g_imgpool8_mul_2 = paddle.multiply(x=g_imgpool8_add, y=g_imgpool8_mul_2_y)
        g_imgpool16_mul_2 = paddle.multiply(x=g_imgpool16_add, y=g_imgpool16_mul_2_y)
        g_imgpool32_mul_2 = paddle.multiply(x=g_imgpool32_add, y=g_imgpool32_mul_2_y)
        g_maskpool2_mul_2 = paddle.multiply(x=g_maskpool2_add, y=g_maskpool2_mul_2_y)
        g_maskpool8_mul_2 = paddle.multiply(x=g_maskpool8_add, y=g_maskpool8_mul_2_y)
        g_maskpool16_mul_2 = paddle.multiply(x=g_maskpool16_add, y=g_maskpool16_mul_2_y)
        g_maskpool32_mul_2 = paddle.multiply(x=g_maskpool32_add, y=g_maskpool32_mul_2_y)
        g_imgpool2_Maximum = paddle.maximum(x=g_imgpool2_mul_2, y=g_imgpool2_add)
        g_imgpool8_Maximum = paddle.maximum(x=g_imgpool8_mul_2, y=g_imgpool8_add)
        g_imgpool16_Maximum = paddle.maximum(x=g_imgpool16_mul_2, y=g_imgpool16_add)
        g_imgpool32_Maximum = paddle.maximum(x=g_imgpool32_mul_2, y=g_imgpool32_add)
        g_maskpool2_Maximum = paddle.maximum(x=g_maskpool2_mul_2, y=g_maskpool2_add)
        g_maskpool8_Maximum = paddle.maximum(x=g_maskpool8_mul_2, y=g_maskpool8_add)
        g_maskpool16_Maximum = paddle.maximum(x=g_maskpool16_mul_2, y=g_maskpool16_add)
        g_maskpool32_Maximum = paddle.maximum(x=g_maskpool32_mul_2, y=g_maskpool32_add)
        resize_bilinear_reshape_10 = paddle.reshape(x=ResizeBilinear_5_size, shape=[2])
        resize_bilinear_reshape_11 = paddle.transpose(x=g_imgpool2_Maximum, perm=[0, 3, 1, 2])
        ResizeBilinear_5 = paddle.nn.functional.interpolate(x=resize_bilinear_reshape_11, size=resize_bilinear_reshape_10, mode='bilinear', align_mode=1)
        ResizeBilinear_5 = paddle.transpose(x=ResizeBilinear_5, perm=[0, 2, 3, 1])
        resize_bilinear_reshape_12 = paddle.reshape(x=ResizeBilinear_6_size, shape=[2])
        resize_bilinear_reshape_13 = paddle.transpose(x=g_imgpool8_Maximum, perm=[0, 3, 1, 2])
        ResizeBilinear_6 = paddle.nn.functional.interpolate(x=resize_bilinear_reshape_13, size=resize_bilinear_reshape_12, mode='bilinear', align_mode=1)
        ResizeBilinear_6 = paddle.transpose(x=ResizeBilinear_6, perm=[0, 2, 3, 1])
        resize_bilinear_reshape_14 = paddle.reshape(x=ResizeBilinear_7_size, shape=[2])
        resize_bilinear_reshape_15 = paddle.transpose(x=g_imgpool16_Maximum, perm=[0, 3, 1, 2])
        ResizeBilinear_7 = paddle.nn.functional.interpolate(x=resize_bilinear_reshape_15, size=resize_bilinear_reshape_14, mode='bilinear', align_mode=1)
        ResizeBilinear_7 = paddle.transpose(x=ResizeBilinear_7, perm=[0, 2, 3, 1])
        resize_bilinear_reshape_16 = paddle.reshape(x=ResizeBilinear_8_size, shape=[2])
        resize_bilinear_reshape_17 = paddle.transpose(x=g_imgpool32_Maximum, perm=[0, 3, 1, 2])
        ResizeBilinear_8 = paddle.nn.functional.interpolate(x=resize_bilinear_reshape_17, size=resize_bilinear_reshape_16, mode='bilinear', align_mode=1)
        ResizeBilinear_8 = paddle.transpose(x=ResizeBilinear_8, perm=[0, 2, 3, 1])
        resize_bilinear_reshape_18 = paddle.reshape(x=ResizeBilinear_9_size, shape=[2])
        resize_bilinear_reshape_19 = paddle.transpose(x=g_maskpool2_Maximum, perm=[0, 3, 1, 2])
        ResizeBilinear_9 = paddle.nn.functional.interpolate(x=resize_bilinear_reshape_19, size=resize_bilinear_reshape_18, mode='bilinear', align_mode=1)
        ResizeBilinear_9 = paddle.transpose(x=ResizeBilinear_9, perm=[0, 2, 3, 1])
        resize_bilinear_reshape_20 = paddle.reshape(x=ResizeBilinear_10_size, shape=[2])
        resize_bilinear_reshape_21 = paddle.transpose(x=g_maskpool8_Maximum, perm=[0, 3, 1, 2])
        ResizeBilinear_10 = paddle.nn.functional.interpolate(x=resize_bilinear_reshape_21, size=resize_bilinear_reshape_20, mode='bilinear', align_mode=1)
        ResizeBilinear_10 = paddle.transpose(x=ResizeBilinear_10, perm=[0, 2, 3, 1])
        resize_bilinear_reshape_22 = paddle.reshape(x=ResizeBilinear_11_size, shape=[2])
        resize_bilinear_reshape_23 = paddle.transpose(x=g_maskpool16_Maximum, perm=[0, 3, 1, 2])
        ResizeBilinear_11 = paddle.nn.functional.interpolate(x=resize_bilinear_reshape_23, size=resize_bilinear_reshape_22, mode='bilinear', align_mode=1)
        ResizeBilinear_11 = paddle.transpose(x=ResizeBilinear_11, perm=[0, 2, 3, 1])
        resize_bilinear_reshape_24 = paddle.reshape(x=ResizeBilinear_12_size, shape=[2])
        resize_bilinear_reshape_25 = paddle.transpose(x=g_maskpool32_Maximum, perm=[0, 3, 1, 2])
        ResizeBilinear_12 = paddle.nn.functional.interpolate(x=resize_bilinear_reshape_25, size=resize_bilinear_reshape_24, mode='bilinear', align_mode=1)
        ResizeBilinear_12 = paddle.transpose(x=ResizeBilinear_12, perm=[0, 2, 3, 1])
        concat_12 = paddle.concat(x=[ResizeBilinear_5, ResizeBilinear_6, ResizeBilinear_7, ResizeBilinear_8, g_aggi_3agg2_Maximum], axis=3)
        concat_13 = paddle.concat(x=[ResizeBilinear_9, ResizeBilinear_10, ResizeBilinear_11, ResizeBilinear_12, g_aggm_3agg2_Maximum], axis=3)
        conv2d_transpose_39 = paddle.transpose(x=concat_12, perm=[0, 3, 1, 2])
        g_imgpoolsf_Conv2D = self.conv39(conv2d_transpose_39)
        g_imgpoolsf_Conv2D = paddle.transpose(x=g_imgpoolsf_Conv2D, perm=[0, 2, 3, 1])
        conv2d_transpose_40 = paddle.transpose(x=concat_13, perm=[0, 3, 1, 2])
        g_maskpoolsf_Conv2D = self.conv40(conv2d_transpose_40)
        g_maskpoolsf_Conv2D = paddle.transpose(x=g_maskpoolsf_Conv2D, perm=[0, 2, 3, 1])
        g_imgpoolsf_mul = paddle.multiply(x=g_imgpoolsf_w0, y=g_imgpoolsf_Conv2D)
        batch_norm_transpose_25 = paddle.transpose(x=g_imgpoolsf_Conv2D, perm=[0, 3, 1, 2])
        g_imgpoolsf_BatchNorm_FusedBatchNorm = self.bn25(batch_norm_transpose_25)
        g_imgpoolsf_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_imgpoolsf_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_maskpoolsf_mul = paddle.multiply(x=g_maskpoolsf_w0, y=g_maskpoolsf_Conv2D)
        batch_norm_transpose_26 = paddle.transpose(x=g_maskpoolsf_Conv2D, perm=[0, 3, 1, 2])
        g_maskpoolsf_BatchNorm_FusedBatchNorm = self.bn26(batch_norm_transpose_26)
        g_maskpoolsf_BatchNorm_FusedBatchNorm = paddle.transpose(x=g_maskpoolsf_BatchNorm_FusedBatchNorm, perm=[0, 2, 3, 1])
        g_imgpoolsf_mul_1 = paddle.multiply(x=g_imgpoolsf_w1, y=g_imgpoolsf_BatchNorm_FusedBatchNorm)
        g_maskpoolsf_mul_1 = paddle.multiply(x=g_maskpoolsf_w1, y=g_maskpoolsf_BatchNorm_FusedBatchNorm)
        g_imgpoolsf_add = paddle.add(x=g_imgpoolsf_mul, y=g_imgpoolsf_mul_1)
        g_maskpoolsf_add = paddle.add(x=g_maskpoolsf_mul, y=g_maskpoolsf_mul_1)
        g_imgpoolsf_mul_2 = paddle.multiply(x=g_imgpoolsf_add, y=g_imgpoolsf_mul_2_y)
        g_maskpoolsf_mul_2 = paddle.multiply(x=g_maskpoolsf_add, y=g_maskpoolsf_mul_2_y)
        g_imgpoolsf_Maximum = paddle.maximum(x=g_imgpoolsf_mul_2, y=g_imgpoolsf_add)
        g_maskpoolsf_Maximum = paddle.maximum(x=g_maskpoolsf_mul_2, y=g_maskpoolsf_add)
        Sigmoid_3 = self.sigmoid11(g_maskpoolsf_Maximum)
        conv2d_transpose_41 = paddle.transpose(x=g_maskpoolsf_Maximum, perm=[0, 3, 1, 2])
        g_conv_mask_Conv2D = self.conv41(conv2d_transpose_41)
        g_conv_mask_BiasAdd = paddle.transpose(x=g_conv_mask_Conv2D, perm=[0, 2, 3, 1])
        mul_4 = paddle.multiply(x=g_imgpoolsf_Maximum, y=Sigmoid_3)
        conv2d_transpose_42 = paddle.transpose(x=mul_4, perm=[0, 3, 1, 2])
        g_conv_img_Conv2D = self.conv42(conv2d_transpose_42)
        g_conv_img_BiasAdd = paddle.transpose(x=g_conv_img_Conv2D, perm=[0, 2, 3, 1])
        return g_conv_img_BiasAdd, g_conv_mask_BiasAdd

def resize_to_test(img, sz=(640, 480)):
    imw, imh = sz
    return cv2.resize(np.float32(img), (imw, imh), cv2.INTER_CUBIC)


def decode_image(img, resize=False, sz=(640, 480)):
    imw, imh = sz
    img = np.squeeze(np.minimum(np.maximum(img, 0.0), 1.0))
    if resize:
        img = resize_to_test(img, sz=(imw, imh))
    img = np.uint8(img * 255.0)
    if len(img.shape) == 2:
        return np.repeat(np.expand_dims(img, axis=2), 3, axis=2)
    else:
        return img

import cv2
import numpy as np
import glob
import os

input_img_dir = 'Dataset/test_dataset/'
output_img_dir = 'Dataset/result/'
test_h = 400
test_w = 300


paddle.disable_static()
params = paddle.load(r'pd_model/model.pdparams')
model = TFModel()
model.set_dict(params, use_structured_name=False)
model.eval()

for image_filename in glob.glob(input_img_dir + '/*.jpg'):

    img = cv2.imread(image_filename, -1)
    src = img.copy()
    img = cv2.resize(np.float32(img), (test_w, test_h), cv2.INTER_CUBIC) / 255.0
    img = img[np.newaxis, :, :, :]
    img = paddle.to_tensor(img)

    oimg, mask = model(img)

    oimg = decode_image(oimg.numpy())
    mask = decode_image(mask.numpy())

    resize_mask = cv2.resize(mask, (src.shape[1], src.shape[0]), interpolation=cv2.INTER_CUBIC)
    resize_oimg = cv2.resize(oimg, (src.shape[1], src.shape[0]), interpolation=cv2.INTER_CUBIC)

    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    resize_mask = cv2.dilate(resize_mask.copy(), kernel) > 0

    src[resize_mask] = resize_oimg[resize_mask]

    if not os.path.isdir(output_img_dir):
        os.makedirs(output_img_dir)
    output_filename = "%s/%s.png" % (output_img_dir, os.path.splitext(os.path.basename(image_filename))[0])
    cv2.imwrite(output_filename, src)
